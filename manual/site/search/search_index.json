{
    "docs": [
        {
            "location": "/", 
            "text": "Log(ML)\n\n\nLog(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.\n\n\nWhy?\n\nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project.\n\nLog(ML)\n performs most of these boring tasks, so you can focus on what's important and adds value.\n\n\nLog(ML)\n performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.\n\n\nLog(ML) Goals: What does Log(ML) do for me?\n\nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad, \nLog(ML)\n creates log file in a systematic manner\n- Save models and results: \nLog(ML)\n saves all your models, so you can always retrieve the best ones.\n\n\nArchitecture: How does Log(ML) work?\n\n\nLog(ML)\n has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.\n\n\nInstall\n\n\nRequirements:\n- Python 3.7\n- Virtual environment\n\n\ngit clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh\n\n\n\n\nThe \nscripts/install.sh\n script should take care of installing in a default directory (\n$HOME/logml\n).\nIf you want another directory, just edit the script and change the \nINSTALL_DIR\n variable\n\n\nNomenclature\n\n\nParameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g. \n{parameter_name}\n\n\nUser defined functions: This are functions defined by the user and marked with the \nLog(ML)\n annotations. For instance, the \"user function decorated with \n@dataset_load\n\" is sometimes referred as the \"\n@dataset_load\n function\", for short\n\n\nWorkflow\n\n\nLog(ML)\n performs the following series of steps (all of them customizable using Python functions and YAML configuration). \nLog(ML)\n allows you to define your own custom functions by adding annotations.\n\n\nHere is a summary of the workflow steps (details are covered in the next sub-sections):\n\n\n\n\nDataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs\n\n\nFeature importance\n\n\nModel Training\n\n\nCross-validation\n\n\nHyper-parameter optimization\n\n\n\n\n\n\nModel Search\n\n\n\n\nEach section can be enabled / disabled and customized in the YAML configuration file.\n\n\nLearning by examples\n\n\nThis is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)\n\n\nIn this section we introduce some examples on how to use \nLog(ML)\n and show how the framework simplifies some aspect fo machine learning projects.\n\n\nBasic setup\n\n\nLog(ML)\n can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.\n\n\nBoth your Python code and the default \nLog(ML)\n implementations require parameters, these parameters are configured in a YAML file.\n\n\nSo, a \nLog(ML)\n project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file\n\n\nExample 1: A neural network for \"XOR\"\n\n\nIn the code shown in \nexample_01.py\n (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n- \nmy_dataset_create\n: Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of \nnum_samples\n row or random numbers in the interval \n[-1, 1]\n. The third column (the output) is the \"XOR\" of the first two columns\n- \nmy_model_create\n: Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with \nnum_neurons\n neurons\n- \nmy_model_train\n: Train the neural network using a learning rate of \nlearning_rate\n and \nepochs\n number of epochs.\n- \nmy_model_eval\n: Evaluate the neural network.\n\n\nNote that the functions are decorated using \nLog(ML)\n decorators \n@dataset_create\n, \n@@model_create\n, \n@model_train\n , \n@model_evaluate\n\n\nPython code \nexample_01.py\n:\n\n\n#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0] \n 0) ^ (x[:, 1] \n 0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()\n\n\n\n\nWe also need to create a configuration YAML file (see below). This YAML file defines three sections:\n- \ndataset\n: Defines the name of the dataset and path to save dataset files.\n- \ntrain\n: Defines the name of the model and path to save model, model parameters and training results files.\n- \nfunctions\n: These define the values to pass to the functions defined in our python program (or \nLog(ML)\n default implementations).\n\n\nConfiguration YAML file \nexample_01.yaml\n\n\ndataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3\n\n\n\n\nA few remarks about the \nfunctions\n section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection \ndataset_create\n is called \nnum_samples\n, which matches the parameter of the Python function annotated with \n@dataset_create\n)\n1. Since our \n@model_evaluate\n function doesn't take any additional arguments than the ones provided by \nLog(ML)\n (i.e. \nmodel\n and \ndataset\n), we don't need to specify the sub-sections in our YAML file\n1. The \n@dataset_split\n function was not implemented in our program, so \nLog(ML)\n will provide a default implementation. This default implementation uses the parameters \nsplit_test\n and \nsplit_validate\n (the dataset is split according to these numbers)\n\n\nNow we can run the program:\n\n\n# By default the expected config file name is \nml.yaml\n so we provide an alternative name name with command line option \n-c\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949\n\n\n\n\nSo, \nLog(ML)\n performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e. \nmy_dataset_create(num_samples=20)\n)\n1. Invoked the function to create a model using as arguments the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_create(dataset, num_neurons=3)\n)\n1. Invoked the function to train the model using as arguments the \nmodel\n, the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_train(model, dataset, learning_rate=0.3, epochs=20)\n)\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments \nmodel\n, and \ndataset_validate\n (since there are no additional parameters from the YAML file)\n\n\nBut \nLog(ML)\n it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file (\nexample_01.pkl\n), the all parameters used to create and train this model (\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n) and the full STDOUT/STDERR (\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\n and \ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\n)\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n\n\n\n\nNow we can change the parameters in the YAML file (for instance set \nlearning_rate: 0.1\n) and run the program again.\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112\n\n\n\n\nAll the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr\n\n\n\n\nExample 2: Hyper-parameter optimization\n\n\nBuilding on the previous example (\nexample_01.py\n and \nexample_01.yaml\n), let's assume that instead of trying to tune the \nlearning_rate\n manually, we'd prefer to perform hyper-parameter optimization.\n\n\nIn this example (\nexample_02\n), we'll set up hyper-parameter optimization on \nlearning_rate\n. The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.\n\n\nFor the config YAML file (see \nexample_02.yaml\n), we jut add the following section:\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nWe added a \nhyper_parameter_optimization\n section where we:\n- Define the hyper parameter algorithm (\ntpe\n) which is a Bayesian apprach\n- Set the number of evaluations to \n100\n\n- Define that we want to optimize the parameter \nlearning_rate\n in the function \n@model_train\n using a uniform prior in the interval \n[0.0, 0.5]\n.\n\n\nWe run the program:\n\n\n$ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06\n00:00,  1.44it/s, best loss: 0.07341234689950943]\n\n\n\n\nHere the hyper-parameter optimization is saying that the best loss found (with ten iterations) is \n0.0734\n.\n\n\nWe also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:\n\n\n$ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml\n\n\n\n\nExample 3: Neural network architecture optimization\n\n\nNow we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the \n@model_create\n step in the workflow). Simply add a line in the \nspace\n definition within \nhyper_parameter_optimization\n section:\n\n\nThe YAML is changed like this (see \nexample_03.yaml\n):\n\n\nhyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...\n\n\n\n\nAlso we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to \n@model_create\n (see line \nnum_neurons = max(num_neurons, 1)\n below):\n\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  # \n-- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n\n\n\nThat's is, we have network architecture optimization (\nnum_neurons\n) and hyper-parameter optimization (\nlearning_rate\n). Let's run the program (output edited for readability):\n\n\n$ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...\n\n\n\n\nThe best parameters, for a 10 iteration hyper-optimization, are \nnum_neurons=3\n and \nlearning_rate=0.2289\n.\n\n\nMain workflow: Overview\n\n\nThe main workflow in \nLog(ML)\n has the following steps (and their respective annotations):\n\n\n\n\nDataset\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\n\n\nDataset\n\n\nBasic feature statistics\n\n\nFeature co-linearity analysis\n\n\nFeature importance\n\n\n\n\n\n\nModel\n\n\nCreate: \n@model_create\n\n\nTrain: \n@model_train\n\n\nSave: \n@model_save\n\n\nSave train results\n\n\nTest: \n@model_evaluate\n\n\nValidate: \n@model_evaluate\n\n\n\n\n\n\n\n\nMain workflow: Dataset\n\n\nThis step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model\n\n\nHere is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:\n\n\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\nYAML config: Dataset section\n\n\nThe config YAML file section for dataset part of the workflow is:\n\n\ndataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?\n\n\n\n\nOther options specific to DataFrames (i.e. \ndataset_type: 'df'\n):\n\n\ndataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold\n\n\n\n\nDataset: Load\n\n\nThis step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).\n\n\n\n\nAttempt to load from pickle file (\n{dataset_path}/{dataset_name}.pkl\n). If the files exists, load the dataset.\n\n\nInvoke a user defined function decorated with \n@dataset_load\n.\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, so \nLog(ML)\n will attempt to create a dataset (next step)\n\n\nParameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_load\n\n\nThe dataset is marked to be saved\n\n\n\n\n\n\n\n\nDataset: Create\n\n\nThis part creates a dataset by invoking the user defined function decorated by \n@dataset_create\n\n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with \n@dataset_create\n:\n    - If there is no user defined function or the section is disabled in the config file (i.e. \nenable=False\n), this step fails. Since \nLog(ML)\n doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_create\n\n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset load default implementation for \ndataset_type='df'\n (i.e. DataFrame) reads a dataFrame from a CSV file using \npandas.read_csv\n\n\nDataset: Transform\n\n\nThis step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_transform\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_transform\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset transform default implementation for \ndataset_type='df'\n (i.e. DataFrame)\n\n\n\n\n\n\n\n\n\n\nExpand date/time features\n\n\nConvert to categorical\n\n\nConvert to one-hot\n\n\nMissing data\n\n\nDrop low standard deviation fields\n\n\n\n\nExpand date/time features\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ndates\n are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns: \n[Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.]\n.\n\n\nConvert to categorical\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ncategories\n are converted into categorical data and converted to a numerical (integer) representation. Category \n-1\n represents missing values.\n\n\nConvert to one-hot\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \nont_hot\n are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then \none_hot_max_cardinality\n is converted to one-hot encoding.\n\n\nIf there are missing values, a column \n*_isna\n is added to the one-hot encoding.\n\n\nMissing data\n:\n\n\nIn any column having missing values that was not converted to date, categorical or one-hot; a new column \n*_na\n is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.\n\n\nDrop low standard deviation fields\n\n\nAll fields having standard deviation equal or lower than \nstd_threshold\n (by default \n0.0\n) are dropped. Using the default value (\nstd_threshold=0.0\n) this means dropping all fields having the exact same value for all samples.\n\n\nDataset: Augment\n\n\nThis step invokes the user defined function \n@augment\n to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_augment\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_augment\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Preprocess\n\n\nThis step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_preprocess\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_preprocess\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Split\n\n\nThis step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_split\n:\n    1. If there is no user defined function \n@dataset_split\n or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_split\n\n    - If the function is invoked, the return value must be a tuple of three datasets: \n(dataset_train, dataset_test, dataset_validate)\n\n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter \nis_use_default_split\n is set to \nFalse\n, the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters \nsplit_test\n and \nsplit_validate\n in section \ndataset_split\n. If these parameters are not defined in the config YAML file, the split section failed (no error is produced)\n\n\nDataset: Save\n\n\nIf the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.\n\n\n\n\nIf the the YAML config variable \ndo_not_save\n is set to \nTrue\n, this step is skipped\n\n\nIf a user defined function decorated with \n@dataset_save\n exists, it is invoked\n\n\nParameters: The first four parameters are \ndataset, dataset_train, dataset_test, dataset_validate\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_save\n\n\n\n\n\n\nOtherwise the dataset is saved to the pickle file \n{dataset_path}/{dataset_name}.pkl\n\n\n\n\nMain workflow: Model\n\n\nIn these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.\n\n\nThe main steps are:\n\n\n\n\nModel Create: \n@model_create\n\n\nModel Train: \n@model_train\n\n\nModel Save: \n@model_save\n\n\nModel Save train results\n\n\nModel Test: \n@model_evaluate\n\n\nModel Validate: \n@model_evaluate\n\n\n\n\nA new \nmodel_id\n is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The \nmodel_id\n has the format \nyyyymmdd_hhmmss.counter\n where:\n    - \nyyyy\n, \nmm\n, \ndd\n, \nhh\n, \nmm\n, \nss\n: Current year, month, day, hour, minute, second (UTC time)\n    - \ncounter\n: Number of models created in this \nLog(ML)\n run (increasing counter starting with \n1\n).\n\n\nLogging\n: All results from STDOUT and STDERR are saved to \n{model_path}/{model_name}.parameters.{model_id}.stdout\n and \n{model_path}/{model_name}.parameters.{model_id}.stderr\n respectively. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each output set to different \nstdout/stderr\n files (see details below).\n\n\nYAML config: Model section\n\n\nmodel:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?\n\n\n\n\nModel: Create\n\n\nCreate a new model, to be trained. It also saves the parameters used to create the model to a YAML file.\n\n\n\n\nIf a user defined function decorated with \n@model_create\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameter is \ndataset_train\n if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_create\n\n\nThe return value from the user defined function is stored as the \nmodel\n\n\n\n\n\n\nCurrent parameters are saved to a YAML file \n{model_path}/{model_name}.parameters.{model_id}.yaml\n. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each parameter set to different YAML files.\n\n\n\n\nModel: Train\n\n\nTrain the model.\n\n\n\n\nIf a user defined function decorated with \n@model_train\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_train\n (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_train\n\n\nThe return value from the user defined function is stored as the \ntrain_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save\n\n\nSave the (trained) model.\n\n\n\n\nIf a user defined function decorated with \n@model_save\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program tries to save using a pickle file (see next step).\n\n\nParameters: The first parameters is the \nmodel\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_save\n\n\nReturn successful\n\n\n\n\n\n\nAttempt to save model to pickle file if previous step (\n@model_save\n function) failed.\n\n\nIf parameter \nis_save_model_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.model.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save each model to different pickle files.\n\n\n\n\n\n\nAttempt to save model to using \nmodel.save()\n if previous step failed.\n\n\nIf parameter \nis_save_model_method\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nInvoke model's method \nmodel.save({file_name})\n, where \nfile_name\n is set to \n{model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}\n (parameter \nis_save_model_method_ext\n is defined in config YAML file)\n\n\n\n\n\n\n\n\nModel: Save train Results\n\n\nSave results from training to a pickle file\n\n\n\n\nAttempt to save model training results (i.e. the return value from \n@model_train\n function) to pickle.\n\n\nIf parameter \nis_save_train_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.train_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Test\n\n\nEvaluate the model on the \ndataset_test\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_test\n (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \ntest_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save test results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_test\n parameter) to pickle.\n\n\nIf parameter \nis_save_test_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.test_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so testing several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Validate\n\n\nEvaluate the model on the \ndataset_validate\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_validate\n (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \nvalidate_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save validate results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_validate\n parameter) to pickle.\n\n\nIf parameter \nis_save_validate_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.validate_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so validating several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nAlternative workflows\n\n\nThere are some \nLog(ML)\n workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation\n\n\nAlternative workflow: Hyper-parameter optimization\n\n\nThis workflow allows to perform hyper-parameter optimization using a Bayesian framework (\nhyper-opt\n). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".\n\n\nThe hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.\n\n\nThe hyper-parameter optimizaition method used is HyperOpt, for details see \nHyperopt documentation\n\n\nTypically, hyper-parameter optimization is used to tune model training parameters. \nLog(ML)\n also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.\n\n\nYAML config\n\n\nYAML configuration of hyper parameter optimization: All parameter are defined in the \nhyper_parameter_optimization\n section.\n\n\nhyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:\n\n\n\n\nSearch space\n: We define parameters for each part we want to optimize (e.g. \npreprocess\n, \nmodel_create\n, etc.).\nThe format for each parameter space is:\n\n\nparameter_name: ['distribution', distribution)parameters...]\n\n\n\n\nFor distribution names and parameters, see: \nsection 'Parameter Expressions'\n\n\nImportant: The parameters space definition should be a subset of the parameters in each \nfunction\n section.\n\n\nExample: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nAlternative workflow: Cross-validation\n\n\nThis workflow is a Cross-Validation method built on top of the Train part of \nLog(ML)\n main workflow.\n\n\nThe YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see \nSciKit's documentation\n\n\ncross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25\n\n\n\n\nAlternative workflow: Data exploration\n\n\nThese steps implement feature exploration and importance analysis.\n\n\n\n\nFeature statistics\n\n\nCo-linearity analysis\n\n\nFeature importance\n\n\n\n\nCommand line argument\n\n\nCommand line options when invoking a \nLog(ML)\n program:\n\n\n-c \nconfig.yaml\n : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose\n\n\n\n\nModel Search\n\n\n\n\nada_boost_classifier\n\n\nada_boost_regressor\n\n\nard_regression\n\n\nbagging_classifier\n\n\nbagging_regressor\n\n\nbayesian_ridge\n\n\nbernoulli_nb\n\n\ncomplement_nb\n\n\ndecision_tree_classifier\n\n\ndecision_tree_regressor\n\n\ndummy_classifier_most_frequent\n\n\ndummy_classifier_prior\n\n\ndummy_classifier_stratified\n\n\ndummy_classifier_uniform\n\n\ndummy_regressor_mean\n\n\ndummy_regressor_median\n\n\nelastic_net_cv\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngaussian_nb\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nhist_gradient_boosting_classifier\n\n\nhist_gradient_boosting_regressor\n\n\nhuber_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nlars_regression\n\n\nlasso_cv_regression\n\n\nlasso_regression\n\n\nlinear_regression\n\n\nlinear_svc\n\n\nlinear_svr\n\n\nlogistic_regression_cv\n\n\nmultinomial_nb\n\n\nnearest_centroid\n\n\nnu_svc\n\n\nnu_svr\n\n\northogonal_matching_pursuit_regression\n\n\npassive_aggressive_classifier\n\n\nperceptron\n\n\nradius_neighbors_classifier\n\n\nradius_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor\n\n\nransac_regressor\n\n\nridge_cv_regression\n\n\nridge_regression\n\n\nsvc\n\n\nsvr\n\n\ntheil_sen_regressor\n\n\n\n\nModel Search with Hyper-parameter optimization:\n\n\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor", 
            "title": "`Log(ML)`"
        }, 
        {
            "location": "/#logml", 
            "text": "Log(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.  Why? \nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project. Log(ML)  performs most of these boring tasks, so you can focus on what's important and adds value.  Log(ML)  performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.  Log(ML) Goals: What does Log(ML) do for me? \nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad,  Log(ML)  creates log file in a systematic manner\n- Save models and results:  Log(ML)  saves all your models, so you can always retrieve the best ones.  Architecture: How does Log(ML) work?  Log(ML)  has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.", 
            "title": "Log(ML)"
        }, 
        {
            "location": "/#install", 
            "text": "Requirements:\n- Python 3.7\n- Virtual environment  git clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh  The  scripts/install.sh  script should take care of installing in a default directory ( $HOME/logml ).\nIf you want another directory, just edit the script and change the  INSTALL_DIR  variable", 
            "title": "Install"
        }, 
        {
            "location": "/#nomenclature", 
            "text": "Parameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g.  {parameter_name}  User defined functions: This are functions defined by the user and marked with the  Log(ML)  annotations. For instance, the \"user function decorated with  @dataset_load \" is sometimes referred as the \" @dataset_load  function\", for short", 
            "title": "Nomenclature"
        }, 
        {
            "location": "/#workflow", 
            "text": "Log(ML)  performs the following series of steps (all of them customizable using Python functions and YAML configuration).  Log(ML)  allows you to define your own custom functions by adding annotations.  Here is a summary of the workflow steps (details are covered in the next sub-sections):   Dataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs  Feature importance  Model Training  Cross-validation  Hyper-parameter optimization    Model Search   Each section can be enabled / disabled and customized in the YAML configuration file.", 
            "title": "Workflow"
        }, 
        {
            "location": "/#learning-by-examples", 
            "text": "This is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)  In this section we introduce some examples on how to use  Log(ML)  and show how the framework simplifies some aspect fo machine learning projects.", 
            "title": "Learning by examples"
        }, 
        {
            "location": "/#basic-setup", 
            "text": "Log(ML)  can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.  Both your Python code and the default  Log(ML)  implementations require parameters, these parameters are configured in a YAML file.  So, a  Log(ML)  project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file", 
            "title": "Basic setup"
        }, 
        {
            "location": "/#example-1-a-neural-network-for-xor", 
            "text": "In the code shown in  example_01.py  (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n-  my_dataset_create : Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of  num_samples  row or random numbers in the interval  [-1, 1] . The third column (the output) is the \"XOR\" of the first two columns\n-  my_model_create : Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with  num_neurons  neurons\n-  my_model_train : Train the neural network using a learning rate of  learning_rate  and  epochs  number of epochs.\n-  my_model_eval : Evaluate the neural network.  Note that the functions are decorated using  Log(ML)  decorators  @dataset_create ,  @@model_create ,  @model_train  ,  @model_evaluate  Python code  example_01.py :  #!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0]   0) ^ (x[:, 1]   0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()  We also need to create a configuration YAML file (see below). This YAML file defines three sections:\n-  dataset : Defines the name of the dataset and path to save dataset files.\n-  train : Defines the name of the model and path to save model, model parameters and training results files.\n-  functions : These define the values to pass to the functions defined in our python program (or  Log(ML)  default implementations).  Configuration YAML file  example_01.yaml  dataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3  A few remarks about the  functions  section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection  dataset_create  is called  num_samples , which matches the parameter of the Python function annotated with  @dataset_create )\n1. Since our  @model_evaluate  function doesn't take any additional arguments than the ones provided by  Log(ML)  (i.e.  model  and  dataset ), we don't need to specify the sub-sections in our YAML file\n1. The  @dataset_split  function was not implemented in our program, so  Log(ML)  will provide a default implementation. This default implementation uses the parameters  split_test  and  split_validate  (the dataset is split according to these numbers)  Now we can run the program:  # By default the expected config file name is  ml.yaml  so we provide an alternative name name with command line option  -c \n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949  So,  Log(ML)  performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e.  my_dataset_create(num_samples=20) )\n1. Invoked the function to create a model using as arguments the  dataset  plus the parameters from the YAML file (i.e.  my_model_create(dataset, num_neurons=3) )\n1. Invoked the function to train the model using as arguments the  model , the  dataset  plus the parameters from the YAML file (i.e.  my_model_train(model, dataset, learning_rate=0.3, epochs=20) )\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments  model , and  dataset_validate  (since there are no additional parameters from the YAML file)  But  Log(ML)  it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file ( example_01.pkl ), the all parameters used to create and train this model ( data/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml ) and the full STDOUT/STDERR ( data/example_01/train/example_01.20190823.212609.830649.1.stdout  and  data/example_01/train/example_01.20190823.212609.830649.1.stderr )  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml  Now we can change the parameters in the YAML file (for instance set  learning_rate: 0.1 ) and run the program again.  $ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112  All the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr", 
            "title": "Example 1: A neural network for \"XOR\""
        }, 
        {
            "location": "/#example-2-hyper-parameter-optimization", 
            "text": "Building on the previous example ( example_01.py  and  example_01.yaml ), let's assume that instead of trying to tune the  learning_rate  manually, we'd prefer to perform hyper-parameter optimization.  In this example ( example_02 ), we'll set up hyper-parameter optimization on  learning_rate . The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.  For the config YAML file (see  example_02.yaml ), we jut add the following section:  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]  We added a  hyper_parameter_optimization  section where we:\n- Define the hyper parameter algorithm ( tpe ) which is a Bayesian apprach\n- Set the number of evaluations to  100 \n- Define that we want to optimize the parameter  learning_rate  in the function  @model_train  using a uniform prior in the interval  [0.0, 0.5] .  We run the program:  $ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06 00:00,  1.44it/s, best loss: 0.07341234689950943]  Here the hyper-parameter optimization is saying that the best loss found (with ten iterations) is  0.0734 .  We also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:  $ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml", 
            "title": "Example 2: Hyper-parameter optimization"
        }, 
        {
            "location": "/#example-3-neural-network-architecture-optimization", 
            "text": "Now we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the  @model_create  step in the workflow). Simply add a line in the  space  definition within  hyper_parameter_optimization  section:  The YAML is changed like this (see  example_03.yaml ):  hyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...  Also we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to  @model_create  (see line  num_neurons = max(num_neurons, 1)  below):  @model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  #  -- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model  That's is, we have network architecture optimization ( num_neurons ) and hyper-parameter optimization ( learning_rate ). Let's run the program (output edited for readability):  $ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...  The best parameters, for a 10 iteration hyper-optimization, are  num_neurons=3  and  learning_rate=0.2289 .", 
            "title": "Example 3: Neural network architecture optimization"
        }, 
        {
            "location": "/#main-workflow-overview", 
            "text": "The main workflow in  Log(ML)  has the following steps (and their respective annotations):   Dataset  Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save    Dataset  Basic feature statistics  Feature co-linearity analysis  Feature importance    Model  Create:  @model_create  Train:  @model_train  Save:  @model_save  Save train results  Test:  @model_evaluate  Validate:  @model_evaluate", 
            "title": "Main workflow: Overview"
        }, 
        {
            "location": "/#main-workflow-dataset", 
            "text": "This step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model  Here is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:   Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save", 
            "title": "Main workflow: Dataset"
        }, 
        {
            "location": "/#yaml-config-dataset-section", 
            "text": "The config YAML file section for dataset part of the workflow is:  dataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?  Other options specific to DataFrames (i.e.  dataset_type: 'df' ):  dataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold", 
            "title": "YAML config: Dataset section"
        }, 
        {
            "location": "/#dataset-load", 
            "text": "This step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).   Attempt to load from pickle file ( {dataset_path}/{dataset_name}.pkl ). If the files exists, load the dataset.  Invoke a user defined function decorated with  @dataset_load .  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, so  Log(ML)  will attempt to create a dataset (next step)  Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_load  The dataset is marked to be saved", 
            "title": "Dataset: Load"
        }, 
        {
            "location": "/#dataset-create", 
            "text": "This part creates a dataset by invoking the user defined function decorated by  @dataset_create \n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with  @dataset_create :\n    - If there is no user defined function or the section is disabled in the config file (i.e.  enable=False ), this step fails. Since  Log(ML)  doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_create \n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset load default implementation for  dataset_type='df'  (i.e. DataFrame) reads a dataFrame from a CSV file using  pandas.read_csv", 
            "title": "Dataset: Create"
        }, 
        {
            "location": "/#dataset-transform", 
            "text": "This step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_transform :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_transform \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset transform default implementation for  dataset_type='df'  (i.e. DataFrame)     Expand date/time features  Convert to categorical  Convert to one-hot  Missing data  Drop low standard deviation fields   Expand date/time features :  Fields defined in the config YAML file, section  dataset , sub-section  dates  are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns:  [Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.] .  Convert to categorical :  Fields defined in the config YAML file, section  dataset , sub-section  categories  are converted into categorical data and converted to a numerical (integer) representation. Category  -1  represents missing values.  Convert to one-hot :  Fields defined in the config YAML file, section  dataset , sub-section  ont_hot  are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then  one_hot_max_cardinality  is converted to one-hot encoding.  If there are missing values, a column  *_isna  is added to the one-hot encoding.  Missing data :  In any column having missing values that was not converted to date, categorical or one-hot; a new column  *_na  is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.  Drop low standard deviation fields  All fields having standard deviation equal or lower than  std_threshold  (by default  0.0 ) are dropped. Using the default value ( std_threshold=0.0 ) this means dropping all fields having the exact same value for all samples.", 
            "title": "Dataset: Transform"
        }, 
        {
            "location": "/#dataset-augment", 
            "text": "This step invokes the user defined function  @augment  to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_augment :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_augment \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Augment"
        }, 
        {
            "location": "/#dataset-preprocess", 
            "text": "This step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_preprocess :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_preprocess \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Preprocess"
        }, 
        {
            "location": "/#dataset-split", 
            "text": "This step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_split :\n    1. If there is no user defined function  @dataset_split  or the section is disabled in the config file (i.e.  enable=False ), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_split \n    - If the function is invoked, the return value must be a tuple of three datasets:  (dataset_train, dataset_test, dataset_validate) \n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter  is_use_default_split  is set to  False , the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters  split_test  and  split_validate  in section  dataset_split . If these parameters are not defined in the config YAML file, the split section failed (no error is produced)", 
            "title": "Dataset: Split"
        }, 
        {
            "location": "/#dataset-save", 
            "text": "If the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.   If the the YAML config variable  do_not_save  is set to  True , this step is skipped  If a user defined function decorated with  @dataset_save  exists, it is invoked  Parameters: The first four parameters are  dataset, dataset_train, dataset_test, dataset_validate . Other parameters are defined in config YAML file section  functions , sub-section  dataset_save    Otherwise the dataset is saved to the pickle file  {dataset_path}/{dataset_name}.pkl", 
            "title": "Dataset: Save"
        }, 
        {
            "location": "/#main-workflow-model", 
            "text": "In these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.  The main steps are:   Model Create:  @model_create  Model Train:  @model_train  Model Save:  @model_save  Model Save train results  Model Test:  @model_evaluate  Model Validate:  @model_evaluate   A new  model_id  is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The  model_id  has the format  yyyymmdd_hhmmss.counter  where:\n    -  yyyy ,  mm ,  dd ,  hh ,  mm ,  ss : Current year, month, day, hour, minute, second (UTC time)\n    -  counter : Number of models created in this  Log(ML)  run (increasing counter starting with  1 ).  Logging : All results from STDOUT and STDERR are saved to  {model_path}/{model_name}.parameters.{model_id}.stdout  and  {model_path}/{model_name}.parameters.{model_id}.stderr  respectively. Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each output set to different  stdout/stderr  files (see details below).", 
            "title": "Main workflow: Model"
        }, 
        {
            "location": "/#yaml-config-model-section", 
            "text": "model:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?", 
            "title": "YAML config: Model section"
        }, 
        {
            "location": "/#model-create", 
            "text": "Create a new model, to be trained. It also saves the parameters used to create the model to a YAML file.   If a user defined function decorated with  @model_create  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameter is  dataset_train  if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section  functions , sub-section  model_create  The return value from the user defined function is stored as the  model    Current parameters are saved to a YAML file  {model_path}/{model_name}.parameters.{model_id}.yaml . Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each parameter set to different YAML files.", 
            "title": "Model: Create"
        }, 
        {
            "location": "/#model-train", 
            "text": "Train the model.   If a user defined function decorated with  @model_train  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_train  (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_train  The return value from the user defined function is stored as the  train_results  (these result will be saved, see later steps)", 
            "title": "Model: Train"
        }, 
        {
            "location": "/#model-save", 
            "text": "Save the (trained) model.   If a user defined function decorated with  @model_save  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program tries to save using a pickle file (see next step).  Parameters: The first parameters is the  model . Other parameters are defined in config YAML file section  functions , sub-section  model_save  Return successful    Attempt to save model to pickle file if previous step ( @model_save  function) failed.  If parameter  is_save_model_pickle  from config YAML file is set to  False , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.model.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save each model to different pickle files.    Attempt to save model to using  model.save()  if previous step failed.  If parameter  is_save_model_method  from config YAML file is set to  False , this step is skipped  Invoke model's method  model.save({file_name}) , where  file_name  is set to  {model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}  (parameter  is_save_model_method_ext  is defined in config YAML file)", 
            "title": "Model: Save"
        }, 
        {
            "location": "/#model-save-train-results", 
            "text": "Save results from training to a pickle file   Attempt to save model training results (i.e. the return value from  @model_train  function) to pickle.  If parameter  is_save_train_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.train_results.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save train Results"
        }, 
        {
            "location": "/#model-test", 
            "text": "Evaluate the model on the  dataset_test  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_test  (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  test_results  (these result will be saved, see later steps)", 
            "title": "Model: Test"
        }, 
        {
            "location": "/#model-save-test-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_test  parameter) to pickle.  If parameter  is_save_test_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.test_results.{model_id}.pkl .  Note that  model_id  is included in the path, so testing several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save test results"
        }, 
        {
            "location": "/#model-validate", 
            "text": "Evaluate the model on the  dataset_validate  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_validate  (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  validate_results  (these result will be saved, see later steps)", 
            "title": "Model: Validate"
        }, 
        {
            "location": "/#model-save-validate-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_validate  parameter) to pickle.  If parameter  is_save_validate_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.validate_results.{model_id}.pkl .  Note that  model_id  is included in the path, so validating several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save validate results"
        }, 
        {
            "location": "/#alternative-workflows", 
            "text": "There are some  Log(ML)  workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation", 
            "title": "Alternative workflows"
        }, 
        {
            "location": "/#alternative-workflow-hyper-parameter-optimization", 
            "text": "This workflow allows to perform hyper-parameter optimization using a Bayesian framework ( hyper-opt ). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".  The hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.  The hyper-parameter optimizaition method used is HyperOpt, for details see  Hyperopt documentation  Typically, hyper-parameter optimization is used to tune model training parameters.  Log(ML)  also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.", 
            "title": "Alternative workflow: Hyper-parameter optimization"
        }, 
        {
            "location": "/#yaml-config", 
            "text": "YAML configuration of hyper parameter optimization: All parameter are defined in the  hyper_parameter_optimization  section.  hyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:  Search space : We define parameters for each part we want to optimize (e.g.  preprocess ,  model_create , etc.).\nThe format for each parameter space is:  parameter_name: ['distribution', distribution)parameters...]  For distribution names and parameters, see:  section 'Parameter Expressions'  Important: The parameters space definition should be a subset of the parameters in each  function  section.  Example: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]", 
            "title": "YAML config"
        }, 
        {
            "location": "/#alternative-workflow-cross-validation", 
            "text": "This workflow is a Cross-Validation method built on top of the Train part of  Log(ML)  main workflow.  The YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see  SciKit's documentation  cross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25", 
            "title": "Alternative workflow: Cross-validation"
        }, 
        {
            "location": "/#alternative-workflow-data-exploration", 
            "text": "These steps implement feature exploration and importance analysis.   Feature statistics  Co-linearity analysis  Feature importance", 
            "title": "Alternative workflow: Data exploration"
        }, 
        {
            "location": "/#command-line-argument", 
            "text": "Command line options when invoking a  Log(ML)  program:  -c  config.yaml  : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose", 
            "title": "Command line argument"
        }, 
        {
            "location": "/#model-search", 
            "text": "ada_boost_classifier  ada_boost_regressor  ard_regression  bagging_classifier  bagging_regressor  bayesian_ridge  bernoulli_nb  complement_nb  decision_tree_classifier  decision_tree_regressor  dummy_classifier_most_frequent  dummy_classifier_prior  dummy_classifier_stratified  dummy_classifier_uniform  dummy_regressor_mean  dummy_regressor_median  elastic_net_cv  extra_trees_classifier  extra_trees_regressor  gaussian_nb  gradient_boosting_classifier  gradient_boosting_regressor  hist_gradient_boosting_classifier  hist_gradient_boosting_regressor  huber_regressor  k_neighbors_classifier  k_neighbors_regressor  lars_regression  lasso_cv_regression  lasso_regression  linear_regression  linear_svc  linear_svr  logistic_regression_cv  multinomial_nb  nearest_centroid  nu_svc  nu_svr  orthogonal_matching_pursuit_regression  passive_aggressive_classifier  perceptron  radius_neighbors_classifier  radius_neighbors_regressor  random_forest_classifier  random_forest_regressor  ransac_regressor  ridge_cv_regression  ridge_regression  svc  svr  theil_sen_regressor", 
            "title": "Model Search"
        }, 
        {
            "location": "/#model-search-with-hyper-parameter-optimization", 
            "text": "extra_trees_classifier  extra_trees_regressor  gradient_boosting_classifier  gradient_boosting_regressor  k_neighbors_classifier  k_neighbors_regressor  random_forest_classifier  random_forest_regressor", 
            "title": "Model Search with Hyper-parameter optimization:"
        }, 
        {
            "location": "/about/", 
            "text": "About\n\n\nThis project is maintained by \nPablo Cingolani\n and supported by \nAstraZeneca\n\n\nBug reports\n\n\nPlease send any bug reports using \nGitHub\n\n\nIMPORTANT:\n In order to reproduce the error condition, you MUST send a minimal example.\nThe example should be: minimal, self contained, and only involve LogMl\n\n\nThis means:\n\n\n\n\nMinimal:\n There should be only a few lines of code, a small dataset and configuration YAML specifically showing the problem (please do not send hundreds of lines of code, Gigabytes of data or your complete ML analysis).\n\n\nSelf contained:\n No additional data should be required to run your example (e.g. I should not need you to send me additional 10TB data files to run the script).\n\n\nOnly LogMl\n: No additional packages should be required to run your example (e.g. I should not need to install programs/packages on my computer to run your example).", 
            "title": "About"
        }, 
        {
            "location": "/about/#about", 
            "text": "This project is maintained by  Pablo Cingolani  and supported by  AstraZeneca", 
            "title": "About"
        }, 
        {
            "location": "/about/#bug-reports", 
            "text": "Please send any bug reports using  GitHub  IMPORTANT:  In order to reproduce the error condition, you MUST send a minimal example.\nThe example should be: minimal, self contained, and only involve LogMl  This means:   Minimal:  There should be only a few lines of code, a small dataset and configuration YAML specifically showing the problem (please do not send hundreds of lines of code, Gigabytes of data or your complete ML analysis).  Self contained:  No additional data should be required to run your example (e.g. I should not need you to send me additional 10TB data files to run the script).  Only LogMl : No additional packages should be required to run your example (e.g. I should not need to install programs/packages on my computer to run your example).", 
            "title": "Bug reports"
        }, 
        {
            "location": "/index0/", 
            "text": "Log(ML)\n\n\nLog(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.\n\n\nWhy?\n\nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project.\n\nLog(ML)\n performs most of these boring tasks, so you can focus on what's important and adds value.\n\n\nLog(ML)\n performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.\n\n\nLog(ML) Goals: What does Log(ML) do for me?\n\nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad, \nLog(ML)\n creates log file in a systematic manner\n- Save models and results: \nLog(ML)\n saves all your models, so you can always retrieve the best ones.\n\n\nArchitecture: How does Log(ML) work?\n\n\nLog(ML)\n has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.\n\n\nInstall\n\n\nRequirements:\n- Python 3.7\n- Virtual environment\n\n\ngit clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh\n\n\n\n\nThe \nscripts/install.sh\n script should take care of installing in a default directory (\n$HOME/logml\n).\nIf you want another directory, just edit the script and change the \nINSTALL_DIR\n variable\n\n\nNomenclature\n\n\nParameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g. \n{parameter_name}\n\n\nUser defined functions: This are functions defined by the user and marked with the \nLog(ML)\n annotations. For instance, the \"user function decorated with \n@dataset_load\n\" is sometimes referred as the \"\n@dataset_load\n function\", for short\n\n\nWorkflow\n\n\nLog(ML)\n performs the following series of steps (all of them customizable using Python functions and YAML configuration). \nLog(ML)\n allows you to define your own custom functions by adding annotations.\n\n\nHere is a summary of the workflow steps (details are covered in the next sub-sections):\n\n\n\n\nDataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs\n\n\nFeature importance\n\n\nModel Training\n\n\nCross-validation\n\n\nHyper-parameter optimization\n\n\n\n\n\n\nModel Search\n\n\n\n\nEach section can be enabled / disabled and customized in the YAML configuration file.\n\n\nLearning by examples\n\n\nThis is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)\n\n\nIn this section we introduce some examples on how to use \nLog(ML)\n and show how the framework simplifies some aspect fo machine learning projects.\n\n\nBasic setup\n\n\nLog(ML)\n can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.\n\n\nBoth your Python code and the default \nLog(ML)\n implementations require parameters, these parameters are configured in a YAML file.\n\n\nSo, a \nLog(ML)\n project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file\n\n\nExample 1: A neural network for \"XOR\"\n\n\nIn the code shown in \nexample_01.py\n (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n- \nmy_dataset_create\n: Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of \nnum_samples\n row or random numbers in the interval \n[-1, 1]\n. The third column (the output) is the \"XOR\" of the first two columns\n- \nmy_model_create\n: Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with \nnum_neurons\n neurons\n- \nmy_model_train\n: Train the neural network using a learning rate of \nlearning_rate\n and \nepochs\n number of epochs.\n- \nmy_model_eval\n: Evaluate the neural network.\n\n\nNote that the functions are decorated using \nLog(ML)\n decorators \n@dataset_create\n, \n@@model_create\n, \n@model_train\n , \n@model_evaluate\n\n\nPython code \nexample_01.py\n:\n\n\n#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0] \n 0) ^ (x[:, 1] \n 0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()\n\n\n\n\nWe also need to create a configuration YAML file (see below). This YAML file defines three sections:\n- \ndataset\n: Defines the name of the dataset and path to save dataset files.\n- \ntrain\n: Defines the name of the model and path to save model, model parameters and training results files.\n- \nfunctions\n: These define the values to pass to the functions defined in our python program (or \nLog(ML)\n default implementations).\n\n\nConfiguration YAML file \nexample_01.yaml\n\n\ndataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3\n\n\n\n\nA few remarks about the \nfunctions\n section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection \ndataset_create\n is called \nnum_samples\n, which matches the parameter of the Python function annotated with \n@dataset_create\n)\n1. Since our \n@model_evaluate\n function doesn't take any additional arguments than the ones provided by \nLog(ML)\n (i.e. \nmodel\n and \ndataset\n), we don't need to specify the sub-sections in our YAML file\n1. The \n@dataset_split\n function was not implemented in our program, so \nLog(ML)\n will provide a default implementation. This default implementation uses the parameters \nsplit_test\n and \nsplit_validate\n (the dataset is split according to these numbers)\n\n\nNow we can run the program:\n\n\n# By default the expected config file name is \nml.yaml\n so we provide an alternative name name with command line option \n-c\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949\n\n\n\n\nSo, \nLog(ML)\n performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e. \nmy_dataset_create(num_samples=20)\n)\n1. Invoked the function to create a model using as arguments the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_create(dataset, num_neurons=3)\n)\n1. Invoked the function to train the model using as arguments the \nmodel\n, the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_train(model, dataset, learning_rate=0.3, epochs=20)\n)\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments \nmodel\n, and \ndataset_validate\n (since there are no additional parameters from the YAML file)\n\n\nBut \nLog(ML)\n it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file (\nexample_01.pkl\n), the all parameters used to create and train this model (\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n) and the full STDOUT/STDERR (\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\n and \ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\n)\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n\n\n\n\nNow we can change the parameters in the YAML file (for instance set \nlearning_rate: 0.1\n) and run the program again.\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112\n\n\n\n\nAll the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr\n\n\n\n\nExample 2: Hyper-parameter optimization\n\n\nBuilding on the previous example (\nexample_01.py\n and \nexample_01.yaml\n), let's assume that instead of trying to tune the \nlearning_rate\n manually, we'd prefer to perform hyper-parameter optimization.\n\n\nIn this example (\nexample_02\n), we'll set up hyper-parameter optimization on \nlearning_rate\n. The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.\n\n\nFor the config YAML file (see \nexample_02.yaml\n), we jut add the following section:\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nWe added a \nhyper_parameter_optimization\n section where we:\n- Define the hyper parameter algorithm (\ntpe\n) which is a Bayesian apprach\n- Set the number of evaluations to \n100\n\n- Define that we want to optimize the parameter \nlearning_rate\n in the function \n@model_train\n using a uniform prior in the interval \n[0.0, 0.5]\n.\n\n\nWe run the program:\n\n\n$ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06\n00:00,  1.44it/s, best loss: 0.07341234689950943]\n\n\n\n\nHere the hyper-parameter optimization is saying that the best loss found (with ten iterations) is \n0.0734\n.\n\n\nWe also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:\n\n\n$ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml\n\n\n\n\nExample 3: Neural network architecture optimization\n\n\nNow we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the \n@model_create\n step in the workflow). Simply add a line in the \nspace\n definition within \nhyper_parameter_optimization\n section:\n\n\nThe YAML is changed like this (see \nexample_03.yaml\n):\n\n\nhyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...\n\n\n\n\nAlso we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to \n@model_create\n (see line \nnum_neurons = max(num_neurons, 1)\n below):\n\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  # \n-- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n\n\n\nThat's is, we have network architecture optimization (\nnum_neurons\n) and hyper-parameter optimization (\nlearning_rate\n). Let's run the program (output edited for readability):\n\n\n$ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...\n\n\n\n\nThe best parameters, for a 10 iteration hyper-optimization, are \nnum_neurons=3\n and \nlearning_rate=0.2289\n.\n\n\nMain workflow: Overview\n\n\nThe main workflow in \nLog(ML)\n has the following steps (and their respective annotations):\n\n\n\n\nDataset\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\n\n\nDataset\n\n\nBasic feature statistics\n\n\nFeature co-linearity analysis\n\n\nFeature importance\n\n\n\n\n\n\nModel\n\n\nCreate: \n@model_create\n\n\nTrain: \n@model_train\n\n\nSave: \n@model_save\n\n\nSave train results\n\n\nTest: \n@model_evaluate\n\n\nValidate: \n@model_evaluate\n\n\n\n\n\n\n\n\nMain workflow: Dataset\n\n\nThis step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model\n\n\nHere is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:\n\n\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\nYAML config: Dataset section\n\n\nThe config YAML file section for dataset part of the workflow is:\n\n\ndataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?\n\n\n\n\nOther options specific to DataFrames (i.e. \ndataset_type: 'df'\n):\n\n\ndataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold\n\n\n\n\nDataset: Load\n\n\nThis step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).\n\n\n\n\nAttempt to load from pickle file (\n{dataset_path}/{dataset_name}.pkl\n). If the files exists, load the dataset.\n\n\nInvoke a user defined function decorated with \n@dataset_load\n.\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, so \nLog(ML)\n will attempt to create a dataset (next step)\n\n\nParameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_load\n\n\nThe dataset is marked to be saved\n\n\n\n\n\n\n\n\nDataset: Create\n\n\nThis part creates a dataset by invoking the user defined function decorated by \n@dataset_create\n\n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with \n@dataset_create\n:\n    - If there is no user defined function or the section is disabled in the config file (i.e. \nenable=False\n), this step fails. Since \nLog(ML)\n doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_create\n\n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset load default implementation for \ndataset_type='df'\n (i.e. DataFrame) reads a dataFrame from a CSV file using \npandas.read_csv\n\n\nDataset: Transform\n\n\nThis step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_transform\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_transform\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset transform default implementation for \ndataset_type='df'\n (i.e. DataFrame)\n\n\n\n\n\n\n\n\n\n\nExpand date/time features\n\n\nConvert to categorical\n\n\nConvert to one-hot\n\n\nMissing data\n\n\nDrop low standard deviation fields\n\n\n\n\nExpand date/time features\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ndates\n are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns: \n[Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.]\n.\n\n\nConvert to categorical\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ncategories\n are converted into categorical data and converted to a numerical (integer) representation. Category \n-1\n represents missing values.\n\n\nConvert to one-hot\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \nont_hot\n are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then \none_hot_max_cardinality\n is converted to one-hot encoding.\n\n\nIf there are missing values, a column \n*_isna\n is added to the one-hot encoding.\n\n\nMissing data\n:\n\n\nIn any column having missing values that was not converted to date, categorical or one-hot; a new column \n*_na\n is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.\n\n\nDrop low standard deviation fields\n\n\nAll fields having standard deviation equal or lower than \nstd_threshold\n (by default \n0.0\n) are dropped. Using the default value (\nstd_threshold=0.0\n) this means dropping all fields having the exact same value for all samples.\n\n\nDataset: Augment\n\n\nThis step invokes the user defined function \n@augment\n to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_augment\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_augment\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Preprocess\n\n\nThis step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_preprocess\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_preprocess\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Split\n\n\nThis step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_split\n:\n    1. If there is no user defined function \n@dataset_split\n or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_split\n\n    - If the function is invoked, the return value must be a tuple of three datasets: \n(dataset_train, dataset_test, dataset_validate)\n\n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter \nis_use_default_split\n is set to \nFalse\n, the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters \nsplit_test\n and \nsplit_validate\n in section \ndataset_split\n. If these parameters are not defined in the config YAML file, the split section failed (no error is produced)\n\n\nDataset: Save\n\n\nIf the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.\n\n\n\n\nIf the the YAML config variable \ndo_not_save\n is set to \nTrue\n, this step is skipped\n\n\nIf a user defined function decorated with \n@dataset_save\n exists, it is invoked\n\n\nParameters: The first four parameters are \ndataset, dataset_train, dataset_test, dataset_validate\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_save\n\n\n\n\n\n\nOtherwise the dataset is saved to the pickle file \n{dataset_path}/{dataset_name}.pkl\n\n\n\n\nMain workflow: Model\n\n\nIn these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.\n\n\nThe main steps are:\n\n\n\n\nModel Create: \n@model_create\n\n\nModel Train: \n@model_train\n\n\nModel Save: \n@model_save\n\n\nModel Save train results\n\n\nModel Test: \n@model_evaluate\n\n\nModel Validate: \n@model_evaluate\n\n\n\n\nA new \nmodel_id\n is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The \nmodel_id\n has the format \nyyyymmdd_hhmmss.counter\n where:\n    - \nyyyy\n, \nmm\n, \ndd\n, \nhh\n, \nmm\n, \nss\n: Current year, month, day, hour, minute, second (UTC time)\n    - \ncounter\n: Number of models created in this \nLog(ML)\n run (increasing counter starting with \n1\n).\n\n\nLogging\n: All results from STDOUT and STDERR are saved to \n{model_path}/{model_name}.parameters.{model_id}.stdout\n and \n{model_path}/{model_name}.parameters.{model_id}.stderr\n respectively. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each output set to different \nstdout/stderr\n files (see details below).\n\n\nYAML config: Model section\n\n\nmodel:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?\n\n\n\n\nModel: Create\n\n\nCreate a new model, to be trained. It also saves the parameters used to create the model to a YAML file.\n\n\n\n\nIf a user defined function decorated with \n@model_create\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameter is \ndataset_train\n if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_create\n\n\nThe return value from the user defined function is stored as the \nmodel\n\n\n\n\n\n\nCurrent parameters are saved to a YAML file \n{model_path}/{model_name}.parameters.{model_id}.yaml\n. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each parameter set to different YAML files.\n\n\n\n\nModel: Train\n\n\nTrain the model.\n\n\n\n\nIf a user defined function decorated with \n@model_train\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_train\n (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_train\n\n\nThe return value from the user defined function is stored as the \ntrain_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save\n\n\nSave the (trained) model.\n\n\n\n\nIf a user defined function decorated with \n@model_save\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program tries to save using a pickle file (see next step).\n\n\nParameters: The first parameters is the \nmodel\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_save\n\n\nReturn successful\n\n\n\n\n\n\nAttempt to save model to pickle file if previous step (\n@model_save\n function) failed.\n\n\nIf parameter \nis_save_model_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.model.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save each model to different pickle files.\n\n\n\n\n\n\nAttempt to save model to using \nmodel.save()\n if previous step failed.\n\n\nIf parameter \nis_save_model_method\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nInvoke model's method \nmodel.save({file_name})\n, where \nfile_name\n is set to \n{model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}\n (parameter \nis_save_model_method_ext\n is defined in config YAML file)\n\n\n\n\n\n\n\n\nModel: Save train Results\n\n\nSave results from training to a pickle file\n\n\n\n\nAttempt to save model training results (i.e. the return value from \n@model_train\n function) to pickle.\n\n\nIf parameter \nis_save_train_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.train_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Test\n\n\nEvaluate the model on the \ndataset_test\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_test\n (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \ntest_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save test results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_test\n parameter) to pickle.\n\n\nIf parameter \nis_save_test_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.test_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so testing several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Validate\n\n\nEvaluate the model on the \ndataset_validate\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_validate\n (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \nvalidate_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save validate results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_validate\n parameter) to pickle.\n\n\nIf parameter \nis_save_validate_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.validate_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so validating several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nAlternative workflows\n\n\nThere are some \nLog(ML)\n workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation\n\n\nAlternative workflow: Hyper-parameter optimization\n\n\nThis workflow allows to perform hyper-parameter optimization using a Bayesian framework (\nhyper-opt\n). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".\n\n\nThe hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.\n\n\nThe hyper-parameter optimizaition method used is HyperOpt, for details see \nHyperopt documentation\n\n\nTypically, hyper-parameter optimization is used to tune model training parameters. \nLog(ML)\n also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.\n\n\nYAML config\n\n\nYAML configuration of hyper parameter optimization: All parameter are defined in the \nhyper_parameter_optimization\n section.\n\n\nhyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:\n\n\n\n\nSearch space\n: We define parameters for each part we want to optimize (e.g. \npreprocess\n, \nmodel_create\n, etc.).\nThe format for each parameter space is:\n\n\nparameter_name: ['distribution', distribution)parameters...]\n\n\n\n\nFor distribution names and parameters, see: \nsection 'Parameter Expressions'\n\n\nImportant: The parameters space definition should be a subset of the parameters in each \nfunction\n section.\n\n\nExample: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nAlternative workflow: Cross-validation\n\n\nThis workflow is a Cross-Validation method built on top of the Train part of \nLog(ML)\n main workflow.\n\n\nThe YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see \nSciKit's documentation\n\n\ncross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25\n\n\n\n\nAlternative workflow: Data exploration\n\n\nThese steps implement feature exploration and importance analysis.\n\n\n\n\nFeature statistics\n\n\nCo-linearity analysis\n\n\nFeature importance\n\n\n\n\nCommand line argument\n\n\nCommand line options when invoking a \nLog(ML)\n program:\n\n\n-c \nconfig.yaml\n : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose\n\n\n\n\nModel Search\n\n\n\n\nada_boost_classifier\n\n\nada_boost_regressor\n\n\nard_regression\n\n\nbagging_classifier\n\n\nbagging_regressor\n\n\nbayesian_ridge\n\n\nbernoulli_nb\n\n\ncomplement_nb\n\n\ndecision_tree_classifier\n\n\ndecision_tree_regressor\n\n\ndummy_classifier_most_frequent\n\n\ndummy_classifier_prior\n\n\ndummy_classifier_stratified\n\n\ndummy_classifier_uniform\n\n\ndummy_regressor_mean\n\n\ndummy_regressor_median\n\n\nelastic_net_cv\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngaussian_nb\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nhist_gradient_boosting_classifier\n\n\nhist_gradient_boosting_regressor\n\n\nhuber_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nlars_regression\n\n\nlasso_cv_regression\n\n\nlasso_regression\n\n\nlinear_regression\n\n\nlinear_svc\n\n\nlinear_svr\n\n\nlogistic_regression_cv\n\n\nmultinomial_nb\n\n\nnearest_centroid\n\n\nnu_svc\n\n\nnu_svr\n\n\northogonal_matching_pursuit_regression\n\n\npassive_aggressive_classifier\n\n\nperceptron\n\n\nradius_neighbors_classifier\n\n\nradius_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor\n\n\nransac_regressor\n\n\nridge_cv_regression\n\n\nridge_regression\n\n\nsvc\n\n\nsvr\n\n\ntheil_sen_regressor\n\n\n\n\nModel Search with Hyper-parameter optimization:\n\n\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor", 
            "title": "`Log(ML)`"
        }, 
        {
            "location": "/index0/#logml", 
            "text": "Log(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.  Why? \nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project. Log(ML)  performs most of these boring tasks, so you can focus on what's important and adds value.  Log(ML)  performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.  Log(ML) Goals: What does Log(ML) do for me? \nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad,  Log(ML)  creates log file in a systematic manner\n- Save models and results:  Log(ML)  saves all your models, so you can always retrieve the best ones.  Architecture: How does Log(ML) work?  Log(ML)  has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.", 
            "title": "Log(ML)"
        }, 
        {
            "location": "/index0/#install", 
            "text": "Requirements:\n- Python 3.7\n- Virtual environment  git clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh  The  scripts/install.sh  script should take care of installing in a default directory ( $HOME/logml ).\nIf you want another directory, just edit the script and change the  INSTALL_DIR  variable", 
            "title": "Install"
        }, 
        {
            "location": "/index0/#nomenclature", 
            "text": "Parameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g.  {parameter_name}  User defined functions: This are functions defined by the user and marked with the  Log(ML)  annotations. For instance, the \"user function decorated with  @dataset_load \" is sometimes referred as the \" @dataset_load  function\", for short", 
            "title": "Nomenclature"
        }, 
        {
            "location": "/index0/#workflow", 
            "text": "Log(ML)  performs the following series of steps (all of them customizable using Python functions and YAML configuration).  Log(ML)  allows you to define your own custom functions by adding annotations.  Here is a summary of the workflow steps (details are covered in the next sub-sections):   Dataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs  Feature importance  Model Training  Cross-validation  Hyper-parameter optimization    Model Search   Each section can be enabled / disabled and customized in the YAML configuration file.", 
            "title": "Workflow"
        }, 
        {
            "location": "/index0/#learning-by-examples", 
            "text": "This is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)  In this section we introduce some examples on how to use  Log(ML)  and show how the framework simplifies some aspect fo machine learning projects.", 
            "title": "Learning by examples"
        }, 
        {
            "location": "/index0/#basic-setup", 
            "text": "Log(ML)  can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.  Both your Python code and the default  Log(ML)  implementations require parameters, these parameters are configured in a YAML file.  So, a  Log(ML)  project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file", 
            "title": "Basic setup"
        }, 
        {
            "location": "/index0/#example-1-a-neural-network-for-xor", 
            "text": "In the code shown in  example_01.py  (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n-  my_dataset_create : Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of  num_samples  row or random numbers in the interval  [-1, 1] . The third column (the output) is the \"XOR\" of the first two columns\n-  my_model_create : Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with  num_neurons  neurons\n-  my_model_train : Train the neural network using a learning rate of  learning_rate  and  epochs  number of epochs.\n-  my_model_eval : Evaluate the neural network.  Note that the functions are decorated using  Log(ML)  decorators  @dataset_create ,  @@model_create ,  @model_train  ,  @model_evaluate  Python code  example_01.py :  #!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0]   0) ^ (x[:, 1]   0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()  We also need to create a configuration YAML file (see below). This YAML file defines three sections:\n-  dataset : Defines the name of the dataset and path to save dataset files.\n-  train : Defines the name of the model and path to save model, model parameters and training results files.\n-  functions : These define the values to pass to the functions defined in our python program (or  Log(ML)  default implementations).  Configuration YAML file  example_01.yaml  dataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3  A few remarks about the  functions  section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection  dataset_create  is called  num_samples , which matches the parameter of the Python function annotated with  @dataset_create )\n1. Since our  @model_evaluate  function doesn't take any additional arguments than the ones provided by  Log(ML)  (i.e.  model  and  dataset ), we don't need to specify the sub-sections in our YAML file\n1. The  @dataset_split  function was not implemented in our program, so  Log(ML)  will provide a default implementation. This default implementation uses the parameters  split_test  and  split_validate  (the dataset is split according to these numbers)  Now we can run the program:  # By default the expected config file name is  ml.yaml  so we provide an alternative name name with command line option  -c \n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949  So,  Log(ML)  performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e.  my_dataset_create(num_samples=20) )\n1. Invoked the function to create a model using as arguments the  dataset  plus the parameters from the YAML file (i.e.  my_model_create(dataset, num_neurons=3) )\n1. Invoked the function to train the model using as arguments the  model , the  dataset  plus the parameters from the YAML file (i.e.  my_model_train(model, dataset, learning_rate=0.3, epochs=20) )\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments  model , and  dataset_validate  (since there are no additional parameters from the YAML file)  But  Log(ML)  it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file ( example_01.pkl ), the all parameters used to create and train this model ( data/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml ) and the full STDOUT/STDERR ( data/example_01/train/example_01.20190823.212609.830649.1.stdout  and  data/example_01/train/example_01.20190823.212609.830649.1.stderr )  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml  Now we can change the parameters in the YAML file (for instance set  learning_rate: 0.1 ) and run the program again.  $ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112  All the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr", 
            "title": "Example 1: A neural network for \"XOR\""
        }, 
        {
            "location": "/index0/#example-2-hyper-parameter-optimization", 
            "text": "Building on the previous example ( example_01.py  and  example_01.yaml ), let's assume that instead of trying to tune the  learning_rate  manually, we'd prefer to perform hyper-parameter optimization.  In this example ( example_02 ), we'll set up hyper-parameter optimization on  learning_rate . The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.  For the config YAML file (see  example_02.yaml ), we jut add the following section:  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]  We added a  hyper_parameter_optimization  section where we:\n- Define the hyper parameter algorithm ( tpe ) which is a Bayesian apprach\n- Set the number of evaluations to  100 \n- Define that we want to optimize the parameter  learning_rate  in the function  @model_train  using a uniform prior in the interval  [0.0, 0.5] .  We run the program:  $ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06 00:00,  1.44it/s, best loss: 0.07341234689950943]  Here the hyper-parameter optimization is saying that the best loss found (with ten iterations) is  0.0734 .  We also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:  $ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml", 
            "title": "Example 2: Hyper-parameter optimization"
        }, 
        {
            "location": "/index0/#example-3-neural-network-architecture-optimization", 
            "text": "Now we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the  @model_create  step in the workflow). Simply add a line in the  space  definition within  hyper_parameter_optimization  section:  The YAML is changed like this (see  example_03.yaml ):  hyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...  Also we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to  @model_create  (see line  num_neurons = max(num_neurons, 1)  below):  @model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  #  -- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model  That's is, we have network architecture optimization ( num_neurons ) and hyper-parameter optimization ( learning_rate ). Let's run the program (output edited for readability):  $ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...  The best parameters, for a 10 iteration hyper-optimization, are  num_neurons=3  and  learning_rate=0.2289 .", 
            "title": "Example 3: Neural network architecture optimization"
        }, 
        {
            "location": "/index0/#main-workflow-overview", 
            "text": "The main workflow in  Log(ML)  has the following steps (and their respective annotations):   Dataset  Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save    Dataset  Basic feature statistics  Feature co-linearity analysis  Feature importance    Model  Create:  @model_create  Train:  @model_train  Save:  @model_save  Save train results  Test:  @model_evaluate  Validate:  @model_evaluate", 
            "title": "Main workflow: Overview"
        }, 
        {
            "location": "/index0/#main-workflow-dataset", 
            "text": "This step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model  Here is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:   Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save", 
            "title": "Main workflow: Dataset"
        }, 
        {
            "location": "/index0/#yaml-config-dataset-section", 
            "text": "The config YAML file section for dataset part of the workflow is:  dataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?  Other options specific to DataFrames (i.e.  dataset_type: 'df' ):  dataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold", 
            "title": "YAML config: Dataset section"
        }, 
        {
            "location": "/index0/#dataset-load", 
            "text": "This step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).   Attempt to load from pickle file ( {dataset_path}/{dataset_name}.pkl ). If the files exists, load the dataset.  Invoke a user defined function decorated with  @dataset_load .  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, so  Log(ML)  will attempt to create a dataset (next step)  Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_load  The dataset is marked to be saved", 
            "title": "Dataset: Load"
        }, 
        {
            "location": "/index0/#dataset-create", 
            "text": "This part creates a dataset by invoking the user defined function decorated by  @dataset_create \n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with  @dataset_create :\n    - If there is no user defined function or the section is disabled in the config file (i.e.  enable=False ), this step fails. Since  Log(ML)  doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_create \n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset load default implementation for  dataset_type='df'  (i.e. DataFrame) reads a dataFrame from a CSV file using  pandas.read_csv", 
            "title": "Dataset: Create"
        }, 
        {
            "location": "/index0/#dataset-transform", 
            "text": "This step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_transform :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_transform \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset transform default implementation for  dataset_type='df'  (i.e. DataFrame)     Expand date/time features  Convert to categorical  Convert to one-hot  Missing data  Drop low standard deviation fields   Expand date/time features :  Fields defined in the config YAML file, section  dataset , sub-section  dates  are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns:  [Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.] .  Convert to categorical :  Fields defined in the config YAML file, section  dataset , sub-section  categories  are converted into categorical data and converted to a numerical (integer) representation. Category  -1  represents missing values.  Convert to one-hot :  Fields defined in the config YAML file, section  dataset , sub-section  ont_hot  are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then  one_hot_max_cardinality  is converted to one-hot encoding.  If there are missing values, a column  *_isna  is added to the one-hot encoding.  Missing data :  In any column having missing values that was not converted to date, categorical or one-hot; a new column  *_na  is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.  Drop low standard deviation fields  All fields having standard deviation equal or lower than  std_threshold  (by default  0.0 ) are dropped. Using the default value ( std_threshold=0.0 ) this means dropping all fields having the exact same value for all samples.", 
            "title": "Dataset: Transform"
        }, 
        {
            "location": "/index0/#dataset-augment", 
            "text": "This step invokes the user defined function  @augment  to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_augment :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_augment \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Augment"
        }, 
        {
            "location": "/index0/#dataset-preprocess", 
            "text": "This step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_preprocess :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_preprocess \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Preprocess"
        }, 
        {
            "location": "/index0/#dataset-split", 
            "text": "This step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_split :\n    1. If there is no user defined function  @dataset_split  or the section is disabled in the config file (i.e.  enable=False ), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_split \n    - If the function is invoked, the return value must be a tuple of three datasets:  (dataset_train, dataset_test, dataset_validate) \n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter  is_use_default_split  is set to  False , the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters  split_test  and  split_validate  in section  dataset_split . If these parameters are not defined in the config YAML file, the split section failed (no error is produced)", 
            "title": "Dataset: Split"
        }, 
        {
            "location": "/index0/#dataset-save", 
            "text": "If the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.   If the the YAML config variable  do_not_save  is set to  True , this step is skipped  If a user defined function decorated with  @dataset_save  exists, it is invoked  Parameters: The first four parameters are  dataset, dataset_train, dataset_test, dataset_validate . Other parameters are defined in config YAML file section  functions , sub-section  dataset_save    Otherwise the dataset is saved to the pickle file  {dataset_path}/{dataset_name}.pkl", 
            "title": "Dataset: Save"
        }, 
        {
            "location": "/index0/#main-workflow-model", 
            "text": "In these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.  The main steps are:   Model Create:  @model_create  Model Train:  @model_train  Model Save:  @model_save  Model Save train results  Model Test:  @model_evaluate  Model Validate:  @model_evaluate   A new  model_id  is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The  model_id  has the format  yyyymmdd_hhmmss.counter  where:\n    -  yyyy ,  mm ,  dd ,  hh ,  mm ,  ss : Current year, month, day, hour, minute, second (UTC time)\n    -  counter : Number of models created in this  Log(ML)  run (increasing counter starting with  1 ).  Logging : All results from STDOUT and STDERR are saved to  {model_path}/{model_name}.parameters.{model_id}.stdout  and  {model_path}/{model_name}.parameters.{model_id}.stderr  respectively. Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each output set to different  stdout/stderr  files (see details below).", 
            "title": "Main workflow: Model"
        }, 
        {
            "location": "/index0/#yaml-config-model-section", 
            "text": "model:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?", 
            "title": "YAML config: Model section"
        }, 
        {
            "location": "/index0/#model-create", 
            "text": "Create a new model, to be trained. It also saves the parameters used to create the model to a YAML file.   If a user defined function decorated with  @model_create  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameter is  dataset_train  if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section  functions , sub-section  model_create  The return value from the user defined function is stored as the  model    Current parameters are saved to a YAML file  {model_path}/{model_name}.parameters.{model_id}.yaml . Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each parameter set to different YAML files.", 
            "title": "Model: Create"
        }, 
        {
            "location": "/index0/#model-train", 
            "text": "Train the model.   If a user defined function decorated with  @model_train  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_train  (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_train  The return value from the user defined function is stored as the  train_results  (these result will be saved, see later steps)", 
            "title": "Model: Train"
        }, 
        {
            "location": "/index0/#model-save", 
            "text": "Save the (trained) model.   If a user defined function decorated with  @model_save  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program tries to save using a pickle file (see next step).  Parameters: The first parameters is the  model . Other parameters are defined in config YAML file section  functions , sub-section  model_save  Return successful    Attempt to save model to pickle file if previous step ( @model_save  function) failed.  If parameter  is_save_model_pickle  from config YAML file is set to  False , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.model.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save each model to different pickle files.    Attempt to save model to using  model.save()  if previous step failed.  If parameter  is_save_model_method  from config YAML file is set to  False , this step is skipped  Invoke model's method  model.save({file_name}) , where  file_name  is set to  {model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}  (parameter  is_save_model_method_ext  is defined in config YAML file)", 
            "title": "Model: Save"
        }, 
        {
            "location": "/index0/#model-save-train-results", 
            "text": "Save results from training to a pickle file   Attempt to save model training results (i.e. the return value from  @model_train  function) to pickle.  If parameter  is_save_train_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.train_results.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save train Results"
        }, 
        {
            "location": "/index0/#model-test", 
            "text": "Evaluate the model on the  dataset_test  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_test  (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  test_results  (these result will be saved, see later steps)", 
            "title": "Model: Test"
        }, 
        {
            "location": "/index0/#model-save-test-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_test  parameter) to pickle.  If parameter  is_save_test_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.test_results.{model_id}.pkl .  Note that  model_id  is included in the path, so testing several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save test results"
        }, 
        {
            "location": "/index0/#model-validate", 
            "text": "Evaluate the model on the  dataset_validate  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_validate  (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  validate_results  (these result will be saved, see later steps)", 
            "title": "Model: Validate"
        }, 
        {
            "location": "/index0/#model-save-validate-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_validate  parameter) to pickle.  If parameter  is_save_validate_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.validate_results.{model_id}.pkl .  Note that  model_id  is included in the path, so validating several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save validate results"
        }, 
        {
            "location": "/index0/#alternative-workflows", 
            "text": "There are some  Log(ML)  workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation", 
            "title": "Alternative workflows"
        }, 
        {
            "location": "/index0/#alternative-workflow-hyper-parameter-optimization", 
            "text": "This workflow allows to perform hyper-parameter optimization using a Bayesian framework ( hyper-opt ). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".  The hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.  The hyper-parameter optimizaition method used is HyperOpt, for details see  Hyperopt documentation  Typically, hyper-parameter optimization is used to tune model training parameters.  Log(ML)  also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.", 
            "title": "Alternative workflow: Hyper-parameter optimization"
        }, 
        {
            "location": "/index0/#yaml-config", 
            "text": "YAML configuration of hyper parameter optimization: All parameter are defined in the  hyper_parameter_optimization  section.  hyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:  Search space : We define parameters for each part we want to optimize (e.g.  preprocess ,  model_create , etc.).\nThe format for each parameter space is:  parameter_name: ['distribution', distribution)parameters...]  For distribution names and parameters, see:  section 'Parameter Expressions'  Important: The parameters space definition should be a subset of the parameters in each  function  section.  Example: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]", 
            "title": "YAML config"
        }, 
        {
            "location": "/index0/#alternative-workflow-cross-validation", 
            "text": "This workflow is a Cross-Validation method built on top of the Train part of  Log(ML)  main workflow.  The YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see  SciKit's documentation  cross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25", 
            "title": "Alternative workflow: Cross-validation"
        }, 
        {
            "location": "/index0/#alternative-workflow-data-exploration", 
            "text": "These steps implement feature exploration and importance analysis.   Feature statistics  Co-linearity analysis  Feature importance", 
            "title": "Alternative workflow: Data exploration"
        }, 
        {
            "location": "/index0/#command-line-argument", 
            "text": "Command line options when invoking a  Log(ML)  program:  -c  config.yaml  : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose", 
            "title": "Command line argument"
        }, 
        {
            "location": "/index0/#model-search", 
            "text": "ada_boost_classifier  ada_boost_regressor  ard_regression  bagging_classifier  bagging_regressor  bayesian_ridge  bernoulli_nb  complement_nb  decision_tree_classifier  decision_tree_regressor  dummy_classifier_most_frequent  dummy_classifier_prior  dummy_classifier_stratified  dummy_classifier_uniform  dummy_regressor_mean  dummy_regressor_median  elastic_net_cv  extra_trees_classifier  extra_trees_regressor  gaussian_nb  gradient_boosting_classifier  gradient_boosting_regressor  hist_gradient_boosting_classifier  hist_gradient_boosting_regressor  huber_regressor  k_neighbors_classifier  k_neighbors_regressor  lars_regression  lasso_cv_regression  lasso_regression  linear_regression  linear_svc  linear_svr  logistic_regression_cv  multinomial_nb  nearest_centroid  nu_svc  nu_svr  orthogonal_matching_pursuit_regression  passive_aggressive_classifier  perceptron  radius_neighbors_classifier  radius_neighbors_regressor  random_forest_classifier  random_forest_regressor  ransac_regressor  ridge_cv_regression  ridge_regression  svc  svr  theil_sen_regressor", 
            "title": "Model Search"
        }, 
        {
            "location": "/index0/#model-search-with-hyper-parameter-optimization", 
            "text": "extra_trees_classifier  extra_trees_regressor  gradient_boosting_classifier  gradient_boosting_regressor  k_neighbors_classifier  k_neighbors_regressor  random_forest_classifier  random_forest_regressor", 
            "title": "Model Search with Hyper-parameter optimization:"
        }, 
        {
            "location": "/index1/", 
            "text": "Log(ML)\n\n\nLog(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.\n\n\nWhy?\n\nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project.\n\nLog(ML)\n performs most of these boring tasks, so you can focus on what's important and adds value.\n\n\nLog(ML)\n performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.\n\n\nLog(ML) Goals: What does Log(ML) do for me?\n\nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad, \nLog(ML)\n creates log file in a systematic manner\n- Save models and results: \nLog(ML)\n saves all your models, so you can always retrieve the best ones.\n\n\nArchitecture: How does Log(ML) work?\n\n\nLog(ML)\n has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.\n\n\nInstall\n\n\nRequirements:\n- Python 3.7\n- Virtual environment\n\n\ngit clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh\n\n\n\n\nThe \nscripts/install.sh\n script should take care of installing in a default directory (\n$HOME/logml\n).\nIf you want another directory, just edit the script and change the \nINSTALL_DIR\n variable\n\n\nNomenclature\n\n\nParameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g. \n{parameter_name}\n\n\nUser defined functions: This are functions defined by the user and marked with the \nLog(ML)\n annotations. For instance, the \"user function decorated with \n@dataset_load\n\" is sometimes referred as the \"\n@dataset_load\n function\", for short\n\n\nWorkflow\n\n\nLog(ML)\n performs the following series of steps (all of them customizable using Python functions and YAML configuration). \nLog(ML)\n allows you to define your own custom functions by adding annotations.\n\n\nHere is a summary of the workflow steps (details are covered in the next sub-sections):\n\n\n\n\nDataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs\n\n\nFeature importance\n\n\nModel Training\n\n\nCross-validation\n\n\nHyper-parameter optimization\n\n\n\n\n\n\nModel Search\n\n\n\n\nEach section can be enabled / disabled and customized in the YAML configuration file.\n\n\nLearning by examples\n\n\nThis is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)\n\n\nIn this section we introduce some examples on how to use \nLog(ML)\n and show how the framework simplifies some aspect fo machine learning projects.\n\n\nBasic setup\n\n\nLog(ML)\n can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.\n\n\nBoth your Python code and the default \nLog(ML)\n implementations require parameters, these parameters are configured in a YAML file.\n\n\nSo, a \nLog(ML)\n project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file\n\n\nExample 1: A neural network for \"XOR\"\n\n\nIn the code shown in \nexample_01.py\n (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n- \nmy_dataset_create\n: Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of \nnum_samples\n row or random numbers in the interval \n[-1, 1]\n. The third column (the output) is the \"XOR\" of the first two columns\n- \nmy_model_create\n: Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with \nnum_neurons\n neurons\n- \nmy_model_train\n: Train the neural network using a learning rate of \nlearning_rate\n and \nepochs\n number of epochs.\n- \nmy_model_eval\n: Evaluate the neural network.\n\n\nNote that the functions are decorated using \nLog(ML)\n decorators \n@dataset_create\n, \n@@model_create\n, \n@model_train\n , \n@model_evaluate\n\n\nPython code \nexample_01.py\n:\n\n\n#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0] \n 0) ^ (x[:, 1] \n 0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()\n\n\n\n\nWe also need to create a configuration YAML file (see below). This YAML file defines three sections:\n- \ndataset\n: Defines the name of the dataset and path to save dataset files.\n- \ntrain\n: Defines the name of the model and path to save model, model parameters and training results files.\n- \nfunctions\n: These define the values to pass to the functions defined in our python program (or \nLog(ML)\n default implementations).\n\n\nConfiguration YAML file \nexample_01.yaml\n\n\ndataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3\n\n\n\n\nA few remarks about the \nfunctions\n section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection \ndataset_create\n is called \nnum_samples\n, which matches the parameter of the Python function annotated with \n@dataset_create\n)\n1. Since our \n@model_evaluate\n function doesn't take any additional arguments than the ones provided by \nLog(ML)\n (i.e. \nmodel\n and \ndataset\n), we don't need to specify the sub-sections in our YAML file\n1. The \n@dataset_split\n function was not implemented in our program, so \nLog(ML)\n will provide a default implementation. This default implementation uses the parameters \nsplit_test\n and \nsplit_validate\n (the dataset is split according to these numbers)\n\n\nNow we can run the program:\n\n\n# By default the expected config file name is \nml.yaml\n so we provide an alternative name name with command line option \n-c\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949\n\n\n\n\nSo, \nLog(ML)\n performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e. \nmy_dataset_create(num_samples=20)\n)\n1. Invoked the function to create a model using as arguments the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_create(dataset, num_neurons=3)\n)\n1. Invoked the function to train the model using as arguments the \nmodel\n, the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_train(model, dataset, learning_rate=0.3, epochs=20)\n)\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments \nmodel\n, and \ndataset_validate\n (since there are no additional parameters from the YAML file)\n\n\nBut \nLog(ML)\n it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file (\nexample_01.pkl\n), the all parameters used to create and train this model (\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n) and the full STDOUT/STDERR (\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\n and \ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\n)\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n\n\n\n\nNow we can change the parameters in the YAML file (for instance set \nlearning_rate: 0.1\n) and run the program again.\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112\n\n\n\n\nAll the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr\n\n\n\n\nExample 2: Hyper-parameter optimization\n\n\nBuilding on the previous example (\nexample_01.py\n and \nexample_01.yaml\n), let's assume that instead of trying to tune the \nlearning_rate\n manually, we'd prefer to perform hyper-parameter optimization.\n\n\nIn this example (\nexample_02\n), we'll set up hyper-parameter optimization on \nlearning_rate\n. The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.\n\n\nFor the config YAML file (see \nexample_02.yaml\n), we jut add the following section:\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nWe added a \nhyper_parameter_optimization\n section where we:\n- Define the hyper parameter algorithm (\ntpe\n) which is a Bayesian apprach\n- Set the number of evaluations to \n100\n\n- Define that we want to optimize the parameter \nlearning_rate\n in the function \n@model_train\n using a uniform prior in the interval \n[0.0, 0.5]\n.\n\n\nWe run the program:\n\n\n$ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06\n00:00,  1.44it/s, best loss: 0.07341234689950943]\n\n\n\n\nHere the hyper-parameter optimization is saying that the best loss found (with ten iterations) is \n0.0734\n.\n\n\nWe also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:\n\n\n$ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml\n\n\n\n\nExample 3: Neural network architecture optimization\n\n\nNow we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the \n@model_create\n step in the workflow). Simply add a line in the \nspace\n definition within \nhyper_parameter_optimization\n section:\n\n\nThe YAML is changed like this (see \nexample_03.yaml\n):\n\n\nhyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...\n\n\n\n\nAlso we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to \n@model_create\n (see line \nnum_neurons = max(num_neurons, 1)\n below):\n\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  # \n-- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n\n\n\nThat's is, we have network architecture optimization (\nnum_neurons\n) and hyper-parameter optimization (\nlearning_rate\n). Let's run the program (output edited for readability):\n\n\n$ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...\n\n\n\n\nThe best parameters, for a 10 iteration hyper-optimization, are \nnum_neurons=3\n and \nlearning_rate=0.2289\n.\n\n\nMain workflow: Overview\n\n\nThe main workflow in \nLog(ML)\n has the following steps (and their respective annotations):\n\n\n\n\nDataset\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\n\n\nDataset\n\n\nBasic feature statistics\n\n\nFeature co-linearity analysis\n\n\nFeature importance\n\n\n\n\n\n\nModel\n\n\nCreate: \n@model_create\n\n\nTrain: \n@model_train\n\n\nSave: \n@model_save\n\n\nSave train results\n\n\nTest: \n@model_evaluate\n\n\nValidate: \n@model_evaluate\n\n\n\n\n\n\n\n\nMain workflow: Dataset\n\n\nThis step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model\n\n\nHere is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:\n\n\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\nYAML config: Dataset section\n\n\nThe config YAML file section for dataset part of the workflow is:\n\n\ndataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?\n\n\n\n\nOther options specific to DataFrames (i.e. \ndataset_type: 'df'\n):\n\n\ndataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold\n\n\n\n\nDataset: Load\n\n\nThis step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).\n\n\n\n\nAttempt to load from pickle file (\n{dataset_path}/{dataset_name}.pkl\n). If the files exists, load the dataset.\n\n\nInvoke a user defined function decorated with \n@dataset_load\n.\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, so \nLog(ML)\n will attempt to create a dataset (next step)\n\n\nParameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_load\n\n\nThe dataset is marked to be saved\n\n\n\n\n\n\n\n\nDataset: Create\n\n\nThis part creates a dataset by invoking the user defined function decorated by \n@dataset_create\n\n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with \n@dataset_create\n:\n    - If there is no user defined function or the section is disabled in the config file (i.e. \nenable=False\n), this step fails. Since \nLog(ML)\n doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_create\n\n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset load default implementation for \ndataset_type='df'\n (i.e. DataFrame) reads a dataFrame from a CSV file using \npandas.read_csv\n\n\nDataset: Transform\n\n\nThis step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_transform\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_transform\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset transform default implementation for \ndataset_type='df'\n (i.e. DataFrame)\n\n\n\n\n\n\n\n\n\n\nExpand date/time features\n\n\nConvert to categorical\n\n\nConvert to one-hot\n\n\nMissing data\n\n\nDrop low standard deviation fields\n\n\n\n\nExpand date/time features\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ndates\n are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns: \n[Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.]\n.\n\n\nConvert to categorical\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ncategories\n are converted into categorical data and converted to a numerical (integer) representation. Category \n-1\n represents missing values.\n\n\nConvert to one-hot\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \nont_hot\n are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then \none_hot_max_cardinality\n is converted to one-hot encoding.\n\n\nIf there are missing values, a column \n*_isna\n is added to the one-hot encoding.\n\n\nMissing data\n:\n\n\nIn any column having missing values that was not converted to date, categorical or one-hot; a new column \n*_na\n is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.\n\n\nDrop low standard deviation fields\n\n\nAll fields having standard deviation equal or lower than \nstd_threshold\n (by default \n0.0\n) are dropped. Using the default value (\nstd_threshold=0.0\n) this means dropping all fields having the exact same value for all samples.\n\n\nDataset: Augment\n\n\nThis step invokes the user defined function \n@augment\n to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_augment\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_augment\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Preprocess\n\n\nThis step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_preprocess\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_preprocess\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Split\n\n\nThis step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_split\n:\n    1. If there is no user defined function \n@dataset_split\n or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_split\n\n    - If the function is invoked, the return value must be a tuple of three datasets: \n(dataset_train, dataset_test, dataset_validate)\n\n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter \nis_use_default_split\n is set to \nFalse\n, the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters \nsplit_test\n and \nsplit_validate\n in section \ndataset_split\n. If these parameters are not defined in the config YAML file, the split section failed (no error is produced)\n\n\nDataset: Save\n\n\nIf the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.\n\n\n\n\nIf the the YAML config variable \ndo_not_save\n is set to \nTrue\n, this step is skipped\n\n\nIf a user defined function decorated with \n@dataset_save\n exists, it is invoked\n\n\nParameters: The first four parameters are \ndataset, dataset_train, dataset_test, dataset_validate\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_save\n\n\n\n\n\n\nOtherwise the dataset is saved to the pickle file \n{dataset_path}/{dataset_name}.pkl\n\n\n\n\nMain workflow: Model\n\n\nIn these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.\n\n\nThe main steps are:\n\n\n\n\nModel Create: \n@model_create\n\n\nModel Train: \n@model_train\n\n\nModel Save: \n@model_save\n\n\nModel Save train results\n\n\nModel Test: \n@model_evaluate\n\n\nModel Validate: \n@model_evaluate\n\n\n\n\nA new \nmodel_id\n is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The \nmodel_id\n has the format \nyyyymmdd_hhmmss.counter\n where:\n    - \nyyyy\n, \nmm\n, \ndd\n, \nhh\n, \nmm\n, \nss\n: Current year, month, day, hour, minute, second (UTC time)\n    - \ncounter\n: Number of models created in this \nLog(ML)\n run (increasing counter starting with \n1\n).\n\n\nLogging\n: All results from STDOUT and STDERR are saved to \n{model_path}/{model_name}.parameters.{model_id}.stdout\n and \n{model_path}/{model_name}.parameters.{model_id}.stderr\n respectively. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each output set to different \nstdout/stderr\n files (see details below).\n\n\nYAML config: Model section\n\n\nmodel:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?\n\n\n\n\nModel: Create\n\n\nCreate a new model, to be trained. It also saves the parameters used to create the model to a YAML file.\n\n\n\n\nIf a user defined function decorated with \n@model_create\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameter is \ndataset_train\n if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_create\n\n\nThe return value from the user defined function is stored as the \nmodel\n\n\n\n\n\n\nCurrent parameters are saved to a YAML file \n{model_path}/{model_name}.parameters.{model_id}.yaml\n. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each parameter set to different YAML files.\n\n\n\n\nModel: Train\n\n\nTrain the model.\n\n\n\n\nIf a user defined function decorated with \n@model_train\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_train\n (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_train\n\n\nThe return value from the user defined function is stored as the \ntrain_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save\n\n\nSave the (trained) model.\n\n\n\n\nIf a user defined function decorated with \n@model_save\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program tries to save using a pickle file (see next step).\n\n\nParameters: The first parameters is the \nmodel\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_save\n\n\nReturn successful\n\n\n\n\n\n\nAttempt to save model to pickle file if previous step (\n@model_save\n function) failed.\n\n\nIf parameter \nis_save_model_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.model.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save each model to different pickle files.\n\n\n\n\n\n\nAttempt to save model to using \nmodel.save()\n if previous step failed.\n\n\nIf parameter \nis_save_model_method\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nInvoke model's method \nmodel.save({file_name})\n, where \nfile_name\n is set to \n{model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}\n (parameter \nis_save_model_method_ext\n is defined in config YAML file)\n\n\n\n\n\n\n\n\nModel: Save train Results\n\n\nSave results from training to a pickle file\n\n\n\n\nAttempt to save model training results (i.e. the return value from \n@model_train\n function) to pickle.\n\n\nIf parameter \nis_save_train_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.train_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Test\n\n\nEvaluate the model on the \ndataset_test\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_test\n (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \ntest_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save test results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_test\n parameter) to pickle.\n\n\nIf parameter \nis_save_test_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.test_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so testing several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Validate\n\n\nEvaluate the model on the \ndataset_validate\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_validate\n (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \nvalidate_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save validate results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_validate\n parameter) to pickle.\n\n\nIf parameter \nis_save_validate_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.validate_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so validating several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nAlternative workflows\n\n\nThere are some \nLog(ML)\n workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation\n\n\nAlternative workflow: Hyper-parameter optimization\n\n\nThis workflow allows to perform hyper-parameter optimization using a Bayesian framework (\nhyper-opt\n). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".\n\n\nThe hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.\n\n\nThe hyper-parameter optimizaition method used is HyperOpt, for details see \nHyperopt documentation\n\n\nTypically, hyper-parameter optimization is used to tune model training parameters. \nLog(ML)\n also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.\n\n\nYAML config\n\n\nYAML configuration of hyper parameter optimization: All parameter are defined in the \nhyper_parameter_optimization\n section.\n\n\nhyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:\n\n\n\n\nSearch space\n: We define parameters for each part we want to optimize (e.g. \npreprocess\n, \nmodel_create\n, etc.).\nThe format for each parameter space is:\n\n\nparameter_name: ['distribution', distribution)parameters...]\n\n\n\n\nFor distribution names and parameters, see: \nsection 'Parameter Expressions'\n\n\nImportant: The parameters space definition should be a subset of the parameters in each \nfunction\n section.\n\n\nExample: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nAlternative workflow: Cross-validation\n\n\nThis workflow is a Cross-Validation method built on top of the Train part of \nLog(ML)\n main workflow.\n\n\nThe YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see \nSciKit's documentation\n\n\ncross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25\n\n\n\n\nAlternative workflow: Data exploration\n\n\nThese steps implement feature exploration and importance analysis.\n\n\n\n\nFeature statistics\n\n\nCo-linearity analysis\n\n\nFeature importance\n\n\n\n\nCommand line argument\n\n\nCommand line options when invoking a \nLog(ML)\n program:\n\n\n-c \nconfig.yaml\n : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose\n\n\n\n\nModel Search\n\n\n\n\nada_boost_classifier\n\n\nada_boost_regressor\n\n\nard_regression\n\n\nbagging_classifier\n\n\nbagging_regressor\n\n\nbayesian_ridge\n\n\nbernoulli_nb\n\n\ncomplement_nb\n\n\ndecision_tree_classifier\n\n\ndecision_tree_regressor\n\n\ndummy_classifier_most_frequent\n\n\ndummy_classifier_prior\n\n\ndummy_classifier_stratified\n\n\ndummy_classifier_uniform\n\n\ndummy_regressor_mean\n\n\ndummy_regressor_median\n\n\nelastic_net_cv\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngaussian_nb\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nhist_gradient_boosting_classifier\n\n\nhist_gradient_boosting_regressor\n\n\nhuber_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nlars_regression\n\n\nlasso_cv_regression\n\n\nlasso_regression\n\n\nlinear_regression\n\n\nlinear_svc\n\n\nlinear_svr\n\n\nlogistic_regression_cv\n\n\nmultinomial_nb\n\n\nnearest_centroid\n\n\nnu_svc\n\n\nnu_svr\n\n\northogonal_matching_pursuit_regression\n\n\npassive_aggressive_classifier\n\n\nperceptron\n\n\nradius_neighbors_classifier\n\n\nradius_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor\n\n\nransac_regressor\n\n\nridge_cv_regression\n\n\nridge_regression\n\n\nsvc\n\n\nsvr\n\n\ntheil_sen_regressor\n\n\n\n\nModel Search with Hyper-parameter optimization:\n\n\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor", 
            "title": "`Log(ML)`"
        }, 
        {
            "location": "/index1/#logml", 
            "text": "Log(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.  Why? \nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project. Log(ML)  performs most of these boring tasks, so you can focus on what's important and adds value.  Log(ML)  performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.  Log(ML) Goals: What does Log(ML) do for me? \nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad,  Log(ML)  creates log file in a systematic manner\n- Save models and results:  Log(ML)  saves all your models, so you can always retrieve the best ones.  Architecture: How does Log(ML) work?  Log(ML)  has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.", 
            "title": "Log(ML)"
        }, 
        {
            "location": "/index1/#install", 
            "text": "Requirements:\n- Python 3.7\n- Virtual environment  git clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh  The  scripts/install.sh  script should take care of installing in a default directory ( $HOME/logml ).\nIf you want another directory, just edit the script and change the  INSTALL_DIR  variable", 
            "title": "Install"
        }, 
        {
            "location": "/index1/#nomenclature", 
            "text": "Parameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g.  {parameter_name}  User defined functions: This are functions defined by the user and marked with the  Log(ML)  annotations. For instance, the \"user function decorated with  @dataset_load \" is sometimes referred as the \" @dataset_load  function\", for short", 
            "title": "Nomenclature"
        }, 
        {
            "location": "/index1/#workflow", 
            "text": "Log(ML)  performs the following series of steps (all of them customizable using Python functions and YAML configuration).  Log(ML)  allows you to define your own custom functions by adding annotations.  Here is a summary of the workflow steps (details are covered in the next sub-sections):   Dataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs  Feature importance  Model Training  Cross-validation  Hyper-parameter optimization    Model Search   Each section can be enabled / disabled and customized in the YAML configuration file.", 
            "title": "Workflow"
        }, 
        {
            "location": "/index1/#learning-by-examples", 
            "text": "This is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)  In this section we introduce some examples on how to use  Log(ML)  and show how the framework simplifies some aspect fo machine learning projects.", 
            "title": "Learning by examples"
        }, 
        {
            "location": "/index1/#basic-setup", 
            "text": "Log(ML)  can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.  Both your Python code and the default  Log(ML)  implementations require parameters, these parameters are configured in a YAML file.  So, a  Log(ML)  project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file", 
            "title": "Basic setup"
        }, 
        {
            "location": "/index1/#example-1-a-neural-network-for-xor", 
            "text": "In the code shown in  example_01.py  (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n-  my_dataset_create : Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of  num_samples  row or random numbers in the interval  [-1, 1] . The third column (the output) is the \"XOR\" of the first two columns\n-  my_model_create : Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with  num_neurons  neurons\n-  my_model_train : Train the neural network using a learning rate of  learning_rate  and  epochs  number of epochs.\n-  my_model_eval : Evaluate the neural network.  Note that the functions are decorated using  Log(ML)  decorators  @dataset_create ,  @@model_create ,  @model_train  ,  @model_evaluate  Python code  example_01.py :  #!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0]   0) ^ (x[:, 1]   0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()  We also need to create a configuration YAML file (see below). This YAML file defines three sections:\n-  dataset : Defines the name of the dataset and path to save dataset files.\n-  train : Defines the name of the model and path to save model, model parameters and training results files.\n-  functions : These define the values to pass to the functions defined in our python program (or  Log(ML)  default implementations).  Configuration YAML file  example_01.yaml  dataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3  A few remarks about the  functions  section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection  dataset_create  is called  num_samples , which matches the parameter of the Python function annotated with  @dataset_create )\n1. Since our  @model_evaluate  function doesn't take any additional arguments than the ones provided by  Log(ML)  (i.e.  model  and  dataset ), we don't need to specify the sub-sections in our YAML file\n1. The  @dataset_split  function was not implemented in our program, so  Log(ML)  will provide a default implementation. This default implementation uses the parameters  split_test  and  split_validate  (the dataset is split according to these numbers)  Now we can run the program:  # By default the expected config file name is  ml.yaml  so we provide an alternative name name with command line option  -c \n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949  So,  Log(ML)  performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e.  my_dataset_create(num_samples=20) )\n1. Invoked the function to create a model using as arguments the  dataset  plus the parameters from the YAML file (i.e.  my_model_create(dataset, num_neurons=3) )\n1. Invoked the function to train the model using as arguments the  model , the  dataset  plus the parameters from the YAML file (i.e.  my_model_train(model, dataset, learning_rate=0.3, epochs=20) )\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments  model , and  dataset_validate  (since there are no additional parameters from the YAML file)  But  Log(ML)  it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file ( example_01.pkl ), the all parameters used to create and train this model ( data/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml ) and the full STDOUT/STDERR ( data/example_01/train/example_01.20190823.212609.830649.1.stdout  and  data/example_01/train/example_01.20190823.212609.830649.1.stderr )  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml  Now we can change the parameters in the YAML file (for instance set  learning_rate: 0.1 ) and run the program again.  $ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112  All the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr", 
            "title": "Example 1: A neural network for \"XOR\""
        }, 
        {
            "location": "/index1/#example-2-hyper-parameter-optimization", 
            "text": "Building on the previous example ( example_01.py  and  example_01.yaml ), let's assume that instead of trying to tune the  learning_rate  manually, we'd prefer to perform hyper-parameter optimization.  In this example ( example_02 ), we'll set up hyper-parameter optimization on  learning_rate . The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.  For the config YAML file (see  example_02.yaml ), we jut add the following section:  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]  We added a  hyper_parameter_optimization  section where we:\n- Define the hyper parameter algorithm ( tpe ) which is a Bayesian apprach\n- Set the number of evaluations to  100 \n- Define that we want to optimize the parameter  learning_rate  in the function  @model_train  using a uniform prior in the interval  [0.0, 0.5] .  We run the program:  $ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06 00:00,  1.44it/s, best loss: 0.07341234689950943]  Here the hyper-parameter optimization is saying that the best loss found (with ten iterations) is  0.0734 .  We also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:  $ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml", 
            "title": "Example 2: Hyper-parameter optimization"
        }, 
        {
            "location": "/index1/#example-3-neural-network-architecture-optimization", 
            "text": "Now we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the  @model_create  step in the workflow). Simply add a line in the  space  definition within  hyper_parameter_optimization  section:  The YAML is changed like this (see  example_03.yaml ):  hyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...  Also we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to  @model_create  (see line  num_neurons = max(num_neurons, 1)  below):  @model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  #  -- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model  That's is, we have network architecture optimization ( num_neurons ) and hyper-parameter optimization ( learning_rate ). Let's run the program (output edited for readability):  $ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...  The best parameters, for a 10 iteration hyper-optimization, are  num_neurons=3  and  learning_rate=0.2289 .", 
            "title": "Example 3: Neural network architecture optimization"
        }, 
        {
            "location": "/index1/#main-workflow-overview", 
            "text": "The main workflow in  Log(ML)  has the following steps (and their respective annotations):   Dataset  Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save    Dataset  Basic feature statistics  Feature co-linearity analysis  Feature importance    Model  Create:  @model_create  Train:  @model_train  Save:  @model_save  Save train results  Test:  @model_evaluate  Validate:  @model_evaluate", 
            "title": "Main workflow: Overview"
        }, 
        {
            "location": "/index1/#main-workflow-dataset", 
            "text": "This step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model  Here is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:   Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save", 
            "title": "Main workflow: Dataset"
        }, 
        {
            "location": "/index1/#yaml-config-dataset-section", 
            "text": "The config YAML file section for dataset part of the workflow is:  dataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?  Other options specific to DataFrames (i.e.  dataset_type: 'df' ):  dataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold", 
            "title": "YAML config: Dataset section"
        }, 
        {
            "location": "/index1/#dataset-load", 
            "text": "This step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).   Attempt to load from pickle file ( {dataset_path}/{dataset_name}.pkl ). If the files exists, load the dataset.  Invoke a user defined function decorated with  @dataset_load .  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, so  Log(ML)  will attempt to create a dataset (next step)  Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_load  The dataset is marked to be saved", 
            "title": "Dataset: Load"
        }, 
        {
            "location": "/index1/#dataset-create", 
            "text": "This part creates a dataset by invoking the user defined function decorated by  @dataset_create \n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with  @dataset_create :\n    - If there is no user defined function or the section is disabled in the config file (i.e.  enable=False ), this step fails. Since  Log(ML)  doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_create \n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset load default implementation for  dataset_type='df'  (i.e. DataFrame) reads a dataFrame from a CSV file using  pandas.read_csv", 
            "title": "Dataset: Create"
        }, 
        {
            "location": "/index1/#dataset-transform", 
            "text": "This step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_transform :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_transform \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset transform default implementation for  dataset_type='df'  (i.e. DataFrame)     Expand date/time features  Convert to categorical  Convert to one-hot  Missing data  Drop low standard deviation fields   Expand date/time features :  Fields defined in the config YAML file, section  dataset , sub-section  dates  are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns:  [Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.] .  Convert to categorical :  Fields defined in the config YAML file, section  dataset , sub-section  categories  are converted into categorical data and converted to a numerical (integer) representation. Category  -1  represents missing values.  Convert to one-hot :  Fields defined in the config YAML file, section  dataset , sub-section  ont_hot  are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then  one_hot_max_cardinality  is converted to one-hot encoding.  If there are missing values, a column  *_isna  is added to the one-hot encoding.  Missing data :  In any column having missing values that was not converted to date, categorical or one-hot; a new column  *_na  is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.  Drop low standard deviation fields  All fields having standard deviation equal or lower than  std_threshold  (by default  0.0 ) are dropped. Using the default value ( std_threshold=0.0 ) this means dropping all fields having the exact same value for all samples.", 
            "title": "Dataset: Transform"
        }, 
        {
            "location": "/index1/#dataset-augment", 
            "text": "This step invokes the user defined function  @augment  to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_augment :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_augment \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Augment"
        }, 
        {
            "location": "/index1/#dataset-preprocess", 
            "text": "This step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_preprocess :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_preprocess \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Preprocess"
        }, 
        {
            "location": "/index1/#dataset-split", 
            "text": "This step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_split :\n    1. If there is no user defined function  @dataset_split  or the section is disabled in the config file (i.e.  enable=False ), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_split \n    - If the function is invoked, the return value must be a tuple of three datasets:  (dataset_train, dataset_test, dataset_validate) \n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter  is_use_default_split  is set to  False , the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters  split_test  and  split_validate  in section  dataset_split . If these parameters are not defined in the config YAML file, the split section failed (no error is produced)", 
            "title": "Dataset: Split"
        }, 
        {
            "location": "/index1/#dataset-save", 
            "text": "If the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.   If the the YAML config variable  do_not_save  is set to  True , this step is skipped  If a user defined function decorated with  @dataset_save  exists, it is invoked  Parameters: The first four parameters are  dataset, dataset_train, dataset_test, dataset_validate . Other parameters are defined in config YAML file section  functions , sub-section  dataset_save    Otherwise the dataset is saved to the pickle file  {dataset_path}/{dataset_name}.pkl", 
            "title": "Dataset: Save"
        }, 
        {
            "location": "/index1/#main-workflow-model", 
            "text": "In these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.  The main steps are:   Model Create:  @model_create  Model Train:  @model_train  Model Save:  @model_save  Model Save train results  Model Test:  @model_evaluate  Model Validate:  @model_evaluate   A new  model_id  is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The  model_id  has the format  yyyymmdd_hhmmss.counter  where:\n    -  yyyy ,  mm ,  dd ,  hh ,  mm ,  ss : Current year, month, day, hour, minute, second (UTC time)\n    -  counter : Number of models created in this  Log(ML)  run (increasing counter starting with  1 ).  Logging : All results from STDOUT and STDERR are saved to  {model_path}/{model_name}.parameters.{model_id}.stdout  and  {model_path}/{model_name}.parameters.{model_id}.stderr  respectively. Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each output set to different  stdout/stderr  files (see details below).", 
            "title": "Main workflow: Model"
        }, 
        {
            "location": "/index1/#yaml-config-model-section", 
            "text": "model:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?", 
            "title": "YAML config: Model section"
        }, 
        {
            "location": "/index1/#model-create", 
            "text": "Create a new model, to be trained. It also saves the parameters used to create the model to a YAML file.   If a user defined function decorated with  @model_create  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameter is  dataset_train  if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section  functions , sub-section  model_create  The return value from the user defined function is stored as the  model    Current parameters are saved to a YAML file  {model_path}/{model_name}.parameters.{model_id}.yaml . Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each parameter set to different YAML files.", 
            "title": "Model: Create"
        }, 
        {
            "location": "/index1/#model-train", 
            "text": "Train the model.   If a user defined function decorated with  @model_train  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_train  (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_train  The return value from the user defined function is stored as the  train_results  (these result will be saved, see later steps)", 
            "title": "Model: Train"
        }, 
        {
            "location": "/index1/#model-save", 
            "text": "Save the (trained) model.   If a user defined function decorated with  @model_save  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program tries to save using a pickle file (see next step).  Parameters: The first parameters is the  model . Other parameters are defined in config YAML file section  functions , sub-section  model_save  Return successful    Attempt to save model to pickle file if previous step ( @model_save  function) failed.  If parameter  is_save_model_pickle  from config YAML file is set to  False , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.model.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save each model to different pickle files.    Attempt to save model to using  model.save()  if previous step failed.  If parameter  is_save_model_method  from config YAML file is set to  False , this step is skipped  Invoke model's method  model.save({file_name}) , where  file_name  is set to  {model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}  (parameter  is_save_model_method_ext  is defined in config YAML file)", 
            "title": "Model: Save"
        }, 
        {
            "location": "/index1/#model-save-train-results", 
            "text": "Save results from training to a pickle file   Attempt to save model training results (i.e. the return value from  @model_train  function) to pickle.  If parameter  is_save_train_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.train_results.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save train Results"
        }, 
        {
            "location": "/index1/#model-test", 
            "text": "Evaluate the model on the  dataset_test  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_test  (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  test_results  (these result will be saved, see later steps)", 
            "title": "Model: Test"
        }, 
        {
            "location": "/index1/#model-save-test-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_test  parameter) to pickle.  If parameter  is_save_test_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.test_results.{model_id}.pkl .  Note that  model_id  is included in the path, so testing several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save test results"
        }, 
        {
            "location": "/index1/#model-validate", 
            "text": "Evaluate the model on the  dataset_validate  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_validate  (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  validate_results  (these result will be saved, see later steps)", 
            "title": "Model: Validate"
        }, 
        {
            "location": "/index1/#model-save-validate-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_validate  parameter) to pickle.  If parameter  is_save_validate_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.validate_results.{model_id}.pkl .  Note that  model_id  is included in the path, so validating several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save validate results"
        }, 
        {
            "location": "/index1/#alternative-workflows", 
            "text": "There are some  Log(ML)  workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation", 
            "title": "Alternative workflows"
        }, 
        {
            "location": "/index1/#alternative-workflow-hyper-parameter-optimization", 
            "text": "This workflow allows to perform hyper-parameter optimization using a Bayesian framework ( hyper-opt ). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".  The hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.  The hyper-parameter optimizaition method used is HyperOpt, for details see  Hyperopt documentation  Typically, hyper-parameter optimization is used to tune model training parameters.  Log(ML)  also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.", 
            "title": "Alternative workflow: Hyper-parameter optimization"
        }, 
        {
            "location": "/index1/#yaml-config", 
            "text": "YAML configuration of hyper parameter optimization: All parameter are defined in the  hyper_parameter_optimization  section.  hyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:  Search space : We define parameters for each part we want to optimize (e.g.  preprocess ,  model_create , etc.).\nThe format for each parameter space is:  parameter_name: ['distribution', distribution)parameters...]  For distribution names and parameters, see:  section 'Parameter Expressions'  Important: The parameters space definition should be a subset of the parameters in each  function  section.  Example: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]", 
            "title": "YAML config"
        }, 
        {
            "location": "/index1/#alternative-workflow-cross-validation", 
            "text": "This workflow is a Cross-Validation method built on top of the Train part of  Log(ML)  main workflow.  The YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see  SciKit's documentation  cross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25", 
            "title": "Alternative workflow: Cross-validation"
        }, 
        {
            "location": "/index1/#alternative-workflow-data-exploration", 
            "text": "These steps implement feature exploration and importance analysis.   Feature statistics  Co-linearity analysis  Feature importance", 
            "title": "Alternative workflow: Data exploration"
        }, 
        {
            "location": "/index1/#command-line-argument", 
            "text": "Command line options when invoking a  Log(ML)  program:  -c  config.yaml  : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose", 
            "title": "Command line argument"
        }, 
        {
            "location": "/index1/#model-search", 
            "text": "ada_boost_classifier  ada_boost_regressor  ard_regression  bagging_classifier  bagging_regressor  bayesian_ridge  bernoulli_nb  complement_nb  decision_tree_classifier  decision_tree_regressor  dummy_classifier_most_frequent  dummy_classifier_prior  dummy_classifier_stratified  dummy_classifier_uniform  dummy_regressor_mean  dummy_regressor_median  elastic_net_cv  extra_trees_classifier  extra_trees_regressor  gaussian_nb  gradient_boosting_classifier  gradient_boosting_regressor  hist_gradient_boosting_classifier  hist_gradient_boosting_regressor  huber_regressor  k_neighbors_classifier  k_neighbors_regressor  lars_regression  lasso_cv_regression  lasso_regression  linear_regression  linear_svc  linear_svr  logistic_regression_cv  multinomial_nb  nearest_centroid  nu_svc  nu_svr  orthogonal_matching_pursuit_regression  passive_aggressive_classifier  perceptron  radius_neighbors_classifier  radius_neighbors_regressor  random_forest_classifier  random_forest_regressor  ransac_regressor  ridge_cv_regression  ridge_regression  svc  svr  theil_sen_regressor", 
            "title": "Model Search"
        }, 
        {
            "location": "/index1/#model-search-with-hyper-parameter-optimization", 
            "text": "extra_trees_classifier  extra_trees_regressor  gradient_boosting_classifier  gradient_boosting_regressor  k_neighbors_classifier  k_neighbors_regressor  random_forest_classifier  random_forest_regressor", 
            "title": "Model Search with Hyper-parameter optimization:"
        }, 
        {
            "location": "/index2/", 
            "text": "Log(ML)\n\n\nLog(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.\n\n\nWhy?\n\nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project.\n\nLog(ML)\n performs most of these boring tasks, so you can focus on what's important and adds value.\n\n\nLog(ML)\n performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.\n\n\nLog(ML) Goals: What does Log(ML) do for me?\n\nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad, \nLog(ML)\n creates log file in a systematic manner\n- Save models and results: \nLog(ML)\n saves all your models, so you can always retrieve the best ones.\n\n\nArchitecture: How does Log(ML) work?\n\n\nLog(ML)\n has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.\n\n\nInstall\n\n\nRequirements:\n- Python 3.7\n- Virtual environment\n\n\ngit clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh\n\n\n\n\nThe \nscripts/install.sh\n script should take care of installing in a default directory (\n$HOME/logml\n).\nIf you want another directory, just edit the script and change the \nINSTALL_DIR\n variable\n\n\nNomenclature\n\n\nParameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g. \n{parameter_name}\n\n\nUser defined functions: This are functions defined by the user and marked with the \nLog(ML)\n annotations. For instance, the \"user function decorated with \n@dataset_load\n\" is sometimes referred as the \"\n@dataset_load\n function\", for short\n\n\nWorkflow\n\n\nLog(ML)\n performs the following series of steps (all of them customizable using Python functions and YAML configuration). \nLog(ML)\n allows you to define your own custom functions by adding annotations.\n\n\nHere is a summary of the workflow steps (details are covered in the next sub-sections):\n\n\n\n\nDataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs\n\n\nFeature importance\n\n\nModel Training\n\n\nCross-validation\n\n\nHyper-parameter optimization\n\n\n\n\n\n\nModel Search\n\n\n\n\nEach section can be enabled / disabled and customized in the YAML configuration file.\n\n\nLearning by examples\n\n\nThis is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)\n\n\nIn this section we introduce some examples on how to use \nLog(ML)\n and show how the framework simplifies some aspect fo machine learning projects.\n\n\nBasic setup\n\n\nLog(ML)\n can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.\n\n\nBoth your Python code and the default \nLog(ML)\n implementations require parameters, these parameters are configured in a YAML file.\n\n\nSo, a \nLog(ML)\n project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file\n\n\nExample 1: A neural network for \"XOR\"\n\n\nIn the code shown in \nexample_01.py\n (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n- \nmy_dataset_create\n: Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of \nnum_samples\n row or random numbers in the interval \n[-1, 1]\n. The third column (the output) is the \"XOR\" of the first two columns\n- \nmy_model_create\n: Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with \nnum_neurons\n neurons\n- \nmy_model_train\n: Train the neural network using a learning rate of \nlearning_rate\n and \nepochs\n number of epochs.\n- \nmy_model_eval\n: Evaluate the neural network.\n\n\nNote that the functions are decorated using \nLog(ML)\n decorators \n@dataset_create\n, \n@@model_create\n, \n@model_train\n , \n@model_evaluate\n\n\nPython code \nexample_01.py\n:\n\n\n#!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0] \n 0) ^ (x[:, 1] \n 0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()\n\n\n\n\nWe also need to create a configuration YAML file (see below). This YAML file defines three sections:\n- \ndataset\n: Defines the name of the dataset and path to save dataset files.\n- \ntrain\n: Defines the name of the model and path to save model, model parameters and training results files.\n- \nfunctions\n: These define the values to pass to the functions defined in our python program (or \nLog(ML)\n default implementations).\n\n\nConfiguration YAML file \nexample_01.yaml\n\n\ndataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3\n\n\n\n\nA few remarks about the \nfunctions\n section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection \ndataset_create\n is called \nnum_samples\n, which matches the parameter of the Python function annotated with \n@dataset_create\n)\n1. Since our \n@model_evaluate\n function doesn't take any additional arguments than the ones provided by \nLog(ML)\n (i.e. \nmodel\n and \ndataset\n), we don't need to specify the sub-sections in our YAML file\n1. The \n@dataset_split\n function was not implemented in our program, so \nLog(ML)\n will provide a default implementation. This default implementation uses the parameters \nsplit_test\n and \nsplit_validate\n (the dataset is split according to these numbers)\n\n\nNow we can run the program:\n\n\n# By default the expected config file name is \nml.yaml\n so we provide an alternative name name with command line option \n-c\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949\n\n\n\n\nSo, \nLog(ML)\n performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e. \nmy_dataset_create(num_samples=20)\n)\n1. Invoked the function to create a model using as arguments the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_create(dataset, num_neurons=3)\n)\n1. Invoked the function to train the model using as arguments the \nmodel\n, the \ndataset\n plus the parameters from the YAML file (i.e. \nmy_model_train(model, dataset, learning_rate=0.3, epochs=20)\n)\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments \nmodel\n, and \ndataset_validate\n (since there are no additional parameters from the YAML file)\n\n\nBut \nLog(ML)\n it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file (\nexample_01.pkl\n), the all parameters used to create and train this model (\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n) and the full STDOUT/STDERR (\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\n and \ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\n)\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\n\n\n\n\nNow we can change the parameters in the YAML file (for instance set \nlearning_rate: 0.1\n) and run the program again.\n\n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112\n\n\n\n\nAll the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.\n\n\n$ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr\n\n\n\n\nExample 2: Hyper-parameter optimization\n\n\nBuilding on the previous example (\nexample_01.py\n and \nexample_01.yaml\n), let's assume that instead of trying to tune the \nlearning_rate\n manually, we'd prefer to perform hyper-parameter optimization.\n\n\nIn this example (\nexample_02\n), we'll set up hyper-parameter optimization on \nlearning_rate\n. The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.\n\n\nFor the config YAML file (see \nexample_02.yaml\n), we jut add the following section:\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nWe added a \nhyper_parameter_optimization\n section where we:\n- Define the hyper parameter algorithm (\ntpe\n) which is a Bayesian apprach\n- Set the number of evaluations to \n100\n\n- Define that we want to optimize the parameter \nlearning_rate\n in the function \n@model_train\n using a uniform prior in the interval \n[0.0, 0.5]\n.\n\n\nWe run the program:\n\n\n$ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06\n00:00,  1.44it/s, best loss: 0.07341234689950943]\n\n\n\n\nHere the hyper-parameter optimization is saying that the best loss found (with ten iterations) is \n0.0734\n.\n\n\nWe also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:\n\n\n$ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml\n\n\n\n\nExample 3: Neural network architecture optimization\n\n\nNow we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the \n@model_create\n step in the workflow). Simply add a line in the \nspace\n definition within \nhyper_parameter_optimization\n section:\n\n\nThe YAML is changed like this (see \nexample_03.yaml\n):\n\n\nhyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...\n\n\n\n\nAlso we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to \n@model_create\n (see line \nnum_neurons = max(num_neurons, 1)\n below):\n\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  # \n-- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n\n\n\nThat's is, we have network architecture optimization (\nnum_neurons\n) and hyper-parameter optimization (\nlearning_rate\n). Let's run the program (output edited for readability):\n\n\n$ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...\n\n\n\n\nThe best parameters, for a 10 iteration hyper-optimization, are \nnum_neurons=3\n and \nlearning_rate=0.2289\n.\n\n\nMain workflow: Overview\n\n\nThe main workflow in \nLog(ML)\n has the following steps (and their respective annotations):\n\n\n\n\nDataset\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\n\n\nDataset\n\n\nBasic feature statistics\n\n\nFeature co-linearity analysis\n\n\nFeature importance\n\n\n\n\n\n\nModel\n\n\nCreate: \n@model_create\n\n\nTrain: \n@model_train\n\n\nSave: \n@model_save\n\n\nSave train results\n\n\nTest: \n@model_evaluate\n\n\nValidate: \n@model_evaluate\n\n\n\n\n\n\n\n\nMain workflow: Dataset\n\n\nThis step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model\n\n\nHere is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:\n\n\n\n\nLoad: \n@dataset_load\n\n\nCreate (if not loaded): \n@dataset_create\n\n\nTransform: \n@dataset_transform\n\n\nAugment: \n@dataset_augment\n\n\nPreprocess: \n@dataset_preprocess\n\n\nSplit: \n@dataset_split\n\n\nSave: \n@dataset_save\n\n\n\n\nYAML config: Dataset section\n\n\nThe config YAML file section for dataset part of the workflow is:\n\n\ndataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?\n\n\n\n\nOther options specific to DataFrames (i.e. \ndataset_type: 'df'\n):\n\n\ndataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold\n\n\n\n\nDataset: Load\n\n\nThis step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).\n\n\n\n\nAttempt to load from pickle file (\n{dataset_path}/{dataset_name}.pkl\n). If the files exists, load the dataset.\n\n\nInvoke a user defined function decorated with \n@dataset_load\n.\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, so \nLog(ML)\n will attempt to create a dataset (next step)\n\n\nParameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_load\n\n\nThe dataset is marked to be saved\n\n\n\n\n\n\n\n\nDataset: Create\n\n\nThis part creates a dataset by invoking the user defined function decorated by \n@dataset_create\n\n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with \n@dataset_create\n:\n    - If there is no user defined function or the section is disabled in the config file (i.e. \nenable=False\n), this step fails. Since \nLog(ML)\n doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section \nfunctions\n, sub-section \ndataset_create\n\n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset load default implementation for \ndataset_type='df'\n (i.e. DataFrame) reads a dataFrame from a CSV file using \npandas.read_csv\n\n\nDataset: Transform\n\n\nThis step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_transform\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_transform\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataFrames:\n Dataset transform default implementation for \ndataset_type='df'\n (i.e. DataFrame)\n\n\n\n\n\n\n\n\n\n\nExpand date/time features\n\n\nConvert to categorical\n\n\nConvert to one-hot\n\n\nMissing data\n\n\nDrop low standard deviation fields\n\n\n\n\nExpand date/time features\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ndates\n are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns: \n[Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.]\n.\n\n\nConvert to categorical\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \ncategories\n are converted into categorical data and converted to a numerical (integer) representation. Category \n-1\n represents missing values.\n\n\nConvert to one-hot\n:\n\n\nFields defined in the config YAML file, section \ndataset\n, sub-section \nont_hot\n are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then \none_hot_max_cardinality\n is converted to one-hot encoding.\n\n\nIf there are missing values, a column \n*_isna\n is added to the one-hot encoding.\n\n\nMissing data\n:\n\n\nIn any column having missing values that was not converted to date, categorical or one-hot; a new column \n*_na\n is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.\n\n\nDrop low standard deviation fields\n\n\nAll fields having standard deviation equal or lower than \nstd_threshold\n (by default \n0.0\n) are dropped. Using the default value (\nstd_threshold=0.0\n) this means dropping all fields having the exact same value for all samples.\n\n\nDataset: Augment\n\n\nThis step invokes the user defined function \n@augment\n to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_augment\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_augment\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Preprocess\n\n\nThis step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_preprocess\n:\n    - If there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_preprocess\n\n    - The return value replaces the original dataset\n    - The dataset is marked to be saved\n\n\nDataset: Split\n\n\nThis step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with \n@dataset_split\n:\n    1. If there is no user defined function \n@dataset_split\n or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_split\n\n    - If the function is invoked, the return value must be a tuple of three datasets: \n(dataset_train, dataset_test, dataset_validate)\n\n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter \nis_use_default_split\n is set to \nFalse\n, the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters \nsplit_test\n and \nsplit_validate\n in section \ndataset_split\n. If these parameters are not defined in the config YAML file, the split section failed (no error is produced)\n\n\nDataset: Save\n\n\nIf the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.\n\n\n\n\nIf the the YAML config variable \ndo_not_save\n is set to \nTrue\n, this step is skipped\n\n\nIf a user defined function decorated with \n@dataset_save\n exists, it is invoked\n\n\nParameters: The first four parameters are \ndataset, dataset_train, dataset_test, dataset_validate\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \ndataset_save\n\n\n\n\n\n\nOtherwise the dataset is saved to the pickle file \n{dataset_path}/{dataset_name}.pkl\n\n\n\n\nMain workflow: Model\n\n\nIn these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.\n\n\nThe main steps are:\n\n\n\n\nModel Create: \n@model_create\n\n\nModel Train: \n@model_train\n\n\nModel Save: \n@model_save\n\n\nModel Save train results\n\n\nModel Test: \n@model_evaluate\n\n\nModel Validate: \n@model_evaluate\n\n\n\n\nA new \nmodel_id\n is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The \nmodel_id\n has the format \nyyyymmdd_hhmmss.counter\n where:\n    - \nyyyy\n, \nmm\n, \ndd\n, \nhh\n, \nmm\n, \nss\n: Current year, month, day, hour, minute, second (UTC time)\n    - \ncounter\n: Number of models created in this \nLog(ML)\n run (increasing counter starting with \n1\n).\n\n\nLogging\n: All results from STDOUT and STDERR are saved to \n{model_path}/{model_name}.parameters.{model_id}.stdout\n and \n{model_path}/{model_name}.parameters.{model_id}.stderr\n respectively. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each output set to different \nstdout/stderr\n files (see details below).\n\n\nYAML config: Model section\n\n\nmodel:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?\n\n\n\n\nModel: Create\n\n\nCreate a new model, to be trained. It also saves the parameters used to create the model to a YAML file.\n\n\n\n\nIf a user defined function decorated with \n@model_create\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameter is \ndataset_train\n if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_create\n\n\nThe return value from the user defined function is stored as the \nmodel\n\n\n\n\n\n\nCurrent parameters are saved to a YAML file \n{model_path}/{model_name}.parameters.{model_id}.yaml\n. Note that \nmodel_id\n is included in the path, so creating several models in the same \nLog(ML)\n run would save each parameter set to different YAML files.\n\n\n\n\nModel: Train\n\n\nTrain the model.\n\n\n\n\nIf a user defined function decorated with \n@model_train\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_train\n (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_train\n\n\nThe return value from the user defined function is stored as the \ntrain_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save\n\n\nSave the (trained) model.\n\n\n\n\nIf a user defined function decorated with \n@model_save\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program tries to save using a pickle file (see next step).\n\n\nParameters: The first parameters is the \nmodel\n. Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_save\n\n\nReturn successful\n\n\n\n\n\n\nAttempt to save model to pickle file if previous step (\n@model_save\n function) failed.\n\n\nIf parameter \nis_save_model_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.model.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save each model to different pickle files.\n\n\n\n\n\n\nAttempt to save model to using \nmodel.save()\n if previous step failed.\n\n\nIf parameter \nis_save_model_method\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nInvoke model's method \nmodel.save({file_name})\n, where \nfile_name\n is set to \n{model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}\n (parameter \nis_save_model_method_ext\n is defined in config YAML file)\n\n\n\n\n\n\n\n\nModel: Save train Results\n\n\nSave results from training to a pickle file\n\n\n\n\nAttempt to save model training results (i.e. the return value from \n@model_train\n function) to pickle.\n\n\nIf parameter \nis_save_train_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.train_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so training several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Test\n\n\nEvaluate the model on the \ndataset_test\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_test\n (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \ntest_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save test results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_test\n parameter) to pickle.\n\n\nIf parameter \nis_save_test_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.test_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so testing several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nModel: Validate\n\n\nEvaluate the model on the \ndataset_validate\n dataset_test\n\n\n\n\nIf a user defined function decorated with \n@model_evaluate\n exists, it is invoked\n\n\nIf there is no function or the section is disabled in the config file (i.e. \nenable=False\n), this step has failed, the program exits with an error.\n\n\nParameters: The first parameters are \nmodel\n and \ndataset_validate\n (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section \nfunctions\n, sub-section \nmodel_evaluate\n\n\nThe return value from the user defined function is stored as the \nvalidate_results\n (these result will be saved, see later steps)\n\n\n\n\n\n\n\n\nModel: Save validate results\n\n\n\n\nAttempt to save model test results (i.e. the return value from \n@model_evaluate\n function invoked with \ndataset_validate\n parameter) to pickle.\n\n\nIf parameter \nis_save_validate_pickle\n from config YAML file is set to \nFalse\n, this step is skipped\n\n\nIf the results are \nNone\n, this step is skipped\n\n\nThe model resulting from training is saved to a pickle file file \n{model_path}/{model_name}.validate_results.{model_id}.pkl\n.\n\n\nNote that \nmodel_id\n is included in the path, so validating several models in the same \nLog(ML)\n run would save train results to different pickle files.\n\n\n\n\n\n\n\n\nAlternative workflows\n\n\nThere are some \nLog(ML)\n workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation\n\n\nAlternative workflow: Hyper-parameter optimization\n\n\nThis workflow allows to perform hyper-parameter optimization using a Bayesian framework (\nhyper-opt\n). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".\n\n\nThe hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.\n\n\nThe hyper-parameter optimizaition method used is HyperOpt, for details see \nHyperopt documentation\n\n\nTypically, hyper-parameter optimization is used to tune model training parameters. \nLog(ML)\n also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.\n\n\nYAML config\n\n\nYAML configuration of hyper parameter optimization: All parameter are defined in the \nhyper_parameter_optimization\n section.\n\n\nhyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:\n\n\n\n\nSearch space\n: We define parameters for each part we want to optimize (e.g. \npreprocess\n, \nmodel_create\n, etc.).\nThe format for each parameter space is:\n\n\nparameter_name: ['distribution', distribution)parameters...]\n\n\n\n\nFor distribution names and parameters, see: \nsection 'Parameter Expressions'\n\n\nImportant: The parameters space definition should be a subset of the parameters in each \nfunction\n section.\n\n\nExample: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nhyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]\n\n\n\n\nAlternative workflow: Cross-validation\n\n\nThis workflow is a Cross-Validation method built on top of the Train part of \nLog(ML)\n main workflow.\n\n\nThe YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see \nSciKit's documentation\n\n\ncross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25\n\n\n\n\nAlternative workflow: Data exploration\n\n\nThese steps implement feature exploration and importance analysis.\n\n\n\n\nFeature statistics\n\n\nCo-linearity analysis\n\n\nFeature importance\n\n\n\n\nCommand line argument\n\n\nCommand line options when invoking a \nLog(ML)\n program:\n\n\n-c \nconfig.yaml\n : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose\n\n\n\n\nModel Search\n\n\n\n\nada_boost_classifier\n\n\nada_boost_regressor\n\n\nard_regression\n\n\nbagging_classifier\n\n\nbagging_regressor\n\n\nbayesian_ridge\n\n\nbernoulli_nb\n\n\ncomplement_nb\n\n\ndecision_tree_classifier\n\n\ndecision_tree_regressor\n\n\ndummy_classifier_most_frequent\n\n\ndummy_classifier_prior\n\n\ndummy_classifier_stratified\n\n\ndummy_classifier_uniform\n\n\ndummy_regressor_mean\n\n\ndummy_regressor_median\n\n\nelastic_net_cv\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngaussian_nb\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nhist_gradient_boosting_classifier\n\n\nhist_gradient_boosting_regressor\n\n\nhuber_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nlars_regression\n\n\nlasso_cv_regression\n\n\nlasso_regression\n\n\nlinear_regression\n\n\nlinear_svc\n\n\nlinear_svr\n\n\nlogistic_regression_cv\n\n\nmultinomial_nb\n\n\nnearest_centroid\n\n\nnu_svc\n\n\nnu_svr\n\n\northogonal_matching_pursuit_regression\n\n\npassive_aggressive_classifier\n\n\nperceptron\n\n\nradius_neighbors_classifier\n\n\nradius_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor\n\n\nransac_regressor\n\n\nridge_cv_regression\n\n\nridge_regression\n\n\nsvc\n\n\nsvr\n\n\ntheil_sen_regressor\n\n\n\n\nModel Search with Hyper-parameter optimization:\n\n\n\n\nextra_trees_classifier\n\n\nextra_trees_regressor\n\n\ngradient_boosting_classifier\n\n\ngradient_boosting_regressor\n\n\nk_neighbors_classifier\n\n\nk_neighbors_regressor\n\n\nrandom_forest_classifier\n\n\nrandom_forest_regressor", 
            "title": "`Log(ML)`"
        }, 
        {
            "location": "/index2/#logml", 
            "text": "Log(ML) is a framework that helps automate many steps in machine learning projects and let you quickly generate baseline results.  Why? \nThere is a considerable amount is setup, boiler-plate code, analysis in every ML/AI project. Log(ML)  performs most of these boring tasks, so you can focus on what's important and adds value.  Log(ML)  performs a consistent data science pipeline, keeping track every action and saving all results and models automatically.  Log(ML) Goals: What does Log(ML) do for me? \nLog(ML) is designed to:\n- Enforce best practices\n- Perform a set of common, well defined, well tested analyses\n- Quickly turn around the first analysis results\n- Facilitates logging in ML projects: No more writing down results in a notepad,  Log(ML)  creates log file in a systematic manner\n- Save models and results:  Log(ML)  saves all your models, so you can always retrieve the best ones.  Architecture: How does Log(ML) work?  Log(ML)  has a standard \"data science workflow\" (a.k.a. pipeline).\nThe workflow include several steps, such as data preprocessing, data augmentation, data exploration, feature importance, model training, hyper-parameter search, cross-validation, etc.\nEach step in the workflow can be customized either in a configuration YAML file or adding custom Python code.", 
            "title": "Log(ML)"
        }, 
        {
            "location": "/index2/#install", 
            "text": "Requirements:\n- Python 3.7\n- Virtual environment  git clone https://github.com/AstraZeneca-NGS/LogMl.git\n\ncd LogMl\n./scripts/install.sh  The  scripts/install.sh  script should take care of installing in a default directory ( $HOME/logml ).\nIf you want another directory, just edit the script and change the  INSTALL_DIR  variable", 
            "title": "Install"
        }, 
        {
            "location": "/index2/#nomenclature", 
            "text": "Parameters from YAML: We refer to parameters defined in YAML file as between curly brackets, e.g.  {parameter_name}  User defined functions: This are functions defined by the user and marked with the  Log(ML)  annotations. For instance, the \"user function decorated with  @dataset_load \" is sometimes referred as the \" @dataset_load  function\", for short", 
            "title": "Nomenclature"
        }, 
        {
            "location": "/index2/#workflow", 
            "text": "Log(ML)  performs the following series of steps (all of them customizable using Python functions and YAML configuration).  Log(ML)  allows you to define your own custom functions by adding annotations.  Here is a summary of the workflow steps (details are covered in the next sub-sections):   Dataset: Load or Create, Transform, Preprocess, Augment, Explore, Split, Inputs/Outputs  Feature importance  Model Training  Cross-validation  Hyper-parameter optimization    Model Search   Each section can be enabled / disabled and customized in the YAML configuration file.", 
            "title": "Workflow"
        }, 
        {
            "location": "/index2/#learning-by-examples", 
            "text": "This is Machine Learning, so let's learn by showing some examples...(hopefully you can generalize as well as your ML algorithms)  In this section we introduce some examples on how to use  Log(ML)  and show how the framework simplifies some aspect fo machine learning projects.", 
            "title": "Learning by examples"
        }, 
        {
            "location": "/index2/#basic-setup", 
            "text": "Log(ML)  can provide some default implementations for some steps of the workflow, but others you need to provide yourself (e.g. code to create your machine learning model). These steps are provided in the Python code you write.  Both your Python code and the default  Log(ML)  implementations require parameters, these parameters are configured in a YAML file.  So, a  Log(ML)  project consist of (at least) two parts:\n1. A Python program\n1. A YAML configuration file", 
            "title": "Basic setup"
        }, 
        {
            "location": "/index2/#example-1-a-neural-network-for-xor", 
            "text": "In the code shown in  example_01.py  (see below)\nwe train a neural network model to learn the \"XOR\" problem. We create three functions:\n-  my_dataset_create : Create a dataset (a NumPy matrix) having the inputs and outputs for our problem. We create two columns (the inputs) of  num_samples  row or random numbers in the interval  [-1, 1] . The third column (the output) is the \"XOR\" of the first two columns\n-  my_model_create : Create a neural network using Tenforflow and Keras sequential mode. The network one hidden layer with  num_neurons  neurons\n-  my_model_train : Train the neural network using a learning rate of  learning_rate  and  epochs  number of epochs.\n-  my_model_eval : Evaluate the neural network.  Note that the functions are decorated using  Log(ML)  decorators  @dataset_create ,  @@model_create ,  @model_train  ,  @model_evaluate  Python code  example_01.py :  #!/usr/bin/env python3\n\nimport numpy as np\nimport tensorflow as tf\nfrom logml import *\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adagrad\n\n@dataset_create\ndef my_dataset_create(num_samples):\n    x = 2 * np.random.rand(num_samples, 2) - 1\n    y = ((x[:, 0]   0) ^ (x[:, 1]   0)).astype('float').reshape(num_samples, 1)\n    return np.concatenate((x, y), axis=1)\n\n@model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model\n\n@model_train\ndef my_model_train(model, dataset, learning_rate, epochs):\n    model.compile(optimizer=Adagrad(lr=learning_rate), loss='mean_squared_error')\n    return model.fit(dataset[:, 0:2], dataset[:, 2], epochs=epochs)\n\n@model_evaluate\ndef my_model_eval(model, dataset):\n    return model.evaluate(dataset[:, 0:2], dataset[:, 2])\n\nml = LogMl()\nml()  We also need to create a configuration YAML file (see below). This YAML file defines three sections:\n-  dataset : Defines the name of the dataset and path to save dataset files.\n-  train : Defines the name of the model and path to save model, model parameters and training results files.\n-  functions : These define the values to pass to the functions defined in our python program (or  Log(ML)  default implementations).  Configuration YAML file  example_01.yaml  dataset:\n  dataset_name: 'example_01'\n  dataset_path: 'data/example_01'\n\nmodel:\n  model_name: 'example_01'\n  model_path: 'data/example_01/model'\n\nfunctions:\n  dataset_create:\n    num_samples: 1000\n  dataset_split:\n    split_test: 0.2\n    split_validate: 0.0\n  model_create:\n      num_neurons: 3\n  model_train:\n    epochs: 20\n    learning_rate: 0.3  A few remarks about the  functions  section:\n1. The name of the parameters in the YAML must match exactly the name of the respective Python functions parameters\n1. Python annotation matches the subsection in the YAML file (e.g. parameters defined YAML subsection  dataset_create  is called  num_samples , which matches the parameter of the Python function annotated with  @dataset_create )\n1. Since our  @model_evaluate  function doesn't take any additional arguments than the ones provided by  Log(ML)  (i.e.  model  and  dataset ), we don't need to specify the sub-sections in our YAML file\n1. The  @dataset_split  function was not implemented in our program, so  Log(ML)  will provide a default implementation. This default implementation uses the parameters  split_test  and  split_validate  (the dataset is split according to these numbers)  Now we can run the program:  # By default the expected config file name is  ml.yaml  so we provide an alternative name name with command line option  -c \n\n$ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 178us/sample - loss: 0.2416\nEpoch 2/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.1588\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 30us/sample - loss: 0.0949  So,  Log(ML)  performed a workflow that:\n1. Invoked the function to create a dataset using the arguments from the YAML file (i.e.  my_dataset_create(num_samples=20) )\n1. Invoked the function to create a model using as arguments the  dataset  plus the parameters from the YAML file (i.e.  my_model_create(dataset, num_neurons=3) )\n1. Invoked the function to train the model using as arguments the  model , the  dataset  plus the parameters from the YAML file (i.e.  my_model_train(model, dataset, learning_rate=0.3, epochs=20) )\n1. Invoked the function to validate the model (evaluate on the validation dataset split) using only as arguments  model , and  dataset_validate  (since there are no additional parameters from the YAML file)  But  Log(ML)  it also did log a lot of information that is useful for future references. In this case, it saved the dataset to a pickle file ( example_01.pkl ), the all parameters used to create and train this model ( data/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml ) and the full STDOUT/STDERR ( data/example_01/train/example_01.20190823.212609.830649.1.stdout  and  data/example_01/train/example_01.20190823.212609.830649.1.stderr )  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml  Now we can change the parameters in the YAML file (for instance set  learning_rate: 0.1 ) and run the program again.  $ ./example_01.py -c example_01.yaml\nEpoch 1/20\n1000/1000 [==============================] - 0s 184us/sample - loss: 0.2561\n...\nEpoch 20/20\n1000/1000 [==============================] - 0s 23us/sample - loss: 0.1112  All the new log files will be created and we can keep track of our project and the parameters we used.\nOK, this model is not as good as the previous one, but fortunately we have all the logging information, so we don't have to remember the parameters we used for the best model.  $ ls data/example_01/* data/example_01/train/*\ndata/example_01/example_01.pkl\ndata/example_01/train/example_01.20190823.213803.075040.1.stdout\ndata/example_01/train/example_01.20190823.212609.830649.1.stderr\ndata/example_01/train/example_01.parameters.20190823.212609.830649.1.yaml\ndata/example_01/train/example_01.20190823.212609.830649.1.stdout\ndata/example_01/train/example_01.parameters.20190823.213803.075040.1.yaml\ndata/example_01/train/example_01.20190823.213803.075040.1.stderr", 
            "title": "Example 1: A neural network for \"XOR\""
        }, 
        {
            "location": "/index2/#example-2-hyper-parameter-optimization", 
            "text": "Building on the previous example ( example_01.py  and  example_01.yaml ), let's assume that instead of trying to tune the  learning_rate  manually, we'd prefer to perform hyper-parameter optimization.  In this example ( example_02 ), we'll set up hyper-parameter optimization on  learning_rate . The python program remains exactly the same as in the previous example, we'll be adding a hyper-parameter optimization section to the YAML file.  For the config YAML file (see  example_02.yaml ), we jut add the following section:  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n          learning_rate: ['uniform', 0.0, 0.5]  We added a  hyper_parameter_optimization  section where we:\n- Define the hyper parameter algorithm ( tpe ) which is a Bayesian apprach\n- Set the number of evaluations to  100 \n- Define that we want to optimize the parameter  learning_rate  in the function  @model_train  using a uniform prior in the interval  [0.0, 0.5] .  We run the program:  $ ./example_02.py -c example_02.yaml\n\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06 00:00,  1.44it/s, best loss: 0.07341234689950943]  Here the hyper-parameter optimization is saying that the best loss found (with ten iterations) is  0.0734 .  We also have all the parameter details, models, and STDOUT/STDERR for every single model created and trained:  $ ls data/example_02/* data/example_02/train/* | cat\ndata/example_02/example_02.pkl\ndata/example_02/train/example_02.20190823.215947.132156.1.stderr\ndata/example_02/train/example_02.20190823.215947.132156.1.stdout\n...\ndata/example_02/train/example_02.20190823.215953.151580.10.stderr\ndata/example_02/train/example_02.20190823.215953.151580.10.stdout\ndata/example_02/train/example_02.hyper_param_search.20190823.215953.151580.10.pkl\ndata/example_02/train/example_02.parameters.20190823.215947.132156.1.yaml\n...\ndata/example_02/train/example_02.parameters.20190823.215953.151580.10.yaml", 
            "title": "Example 2: Hyper-parameter optimization"
        }, 
        {
            "location": "/index2/#example-3-neural-network-architecture-optimization", 
            "text": "Now we build on the previous example (Example 2) by trying to optimize the neural network architecture. For this we just need to add a hyper parameter optimization when building the neural network (i.e. the  @model_create  step in the workflow). Simply add a line in the  space  definition within  hyper_parameter_optimization  section:  The YAML is changed like this (see  example_03.yaml ):  hyper_parameter_optimization:\n    ...\n    space:\n        model_create:\n          num_neurons: ['randint', 5]\n        ...  Also we need a minor change in the python program is to ensure that we at least have one neuron in the hidden layer (otherwise the model doesn't make sense) So we add a single line to  @model_create  (see line  num_neurons = max(num_neurons, 1)  below):  @model_create\ndef my_model_create(dataset, num_neurons):\n    model = Sequential()\n    num_neurons = max(num_neurons, 1)                                  #  -- Added this line\n    model.add(Dense(num_neurons, activation='tanh', input_shape=(2,)))\n    model.add(Dense(1, activation='tanh'))\n    return model  That's is, we have network architecture optimization ( num_neurons ) and hyper-parameter optimization ( learning_rate ). Let's run the program (output edited for readability):  $ ./example_03.py -v -c example_03.yaml\n...\n2019-08-23 21:29:51,924 INFO Hyper parameter optimization:  iteration: 10   ...\n    best fit: 0.06886020198464393\n    best parameters: {'model_create': {'num_neurons': 3}, 'model_train': {'learning_rate': 0.22890998206259194}}\n...  The best parameters, for a 10 iteration hyper-optimization, are  num_neurons=3  and  learning_rate=0.2289 .", 
            "title": "Example 3: Neural network architecture optimization"
        }, 
        {
            "location": "/index2/#main-workflow-overview", 
            "text": "The main workflow in  Log(ML)  has the following steps (and their respective annotations):   Dataset  Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save    Dataset  Basic feature statistics  Feature co-linearity analysis  Feature importance    Model  Create:  @model_create  Train:  @model_train  Save:  @model_save  Save train results  Test:  @model_evaluate  Validate:  @model_evaluate", 
            "title": "Main workflow: Overview"
        }, 
        {
            "location": "/index2/#main-workflow-dataset", 
            "text": "This step takes care of loading or creating a dataset. There are several sub-steps taking care of different aspects of dataset processing to make sure is suitable for training a model  Here is an overview of \"dataset\" workflow is organized. Each sub-section below shows details for specific steps:   Load:  @dataset_load  Create (if not loaded):  @dataset_create  Transform:  @dataset_transform  Augment:  @dataset_augment  Preprocess:  @dataset_preprocess  Split:  @dataset_split  Save:  @dataset_save", 
            "title": "Main workflow: Dataset"
        }, 
        {
            "location": "/index2/#yaml-config-dataset-section", 
            "text": "The config YAML file section for dataset part of the workflow is:  dataset:\n  dataset_name: 'my_dataset'       # Dataset name\n  dataset_path: 'data/my_dataset'  # Path to use when loading and saving datasets\n  dataset_type: None               # Dataset type: 'df' means dataFrame (if this option is commented out then a custom object is assumed)\n  is_use_default_split: False      # Use (internal) 'split' function if none is provided by the user?  Other options specific to DataFrames (i.e.  dataset_type: 'df' ):  dataset:\n  dataset_type: 'df'\n  ...\n  categories:                                      # Define categorical data columns\n    category_name_1: ['Small', 'Medium', 'Large']  # Force this column to be converted to a catergory, set categories as ['Small', 'Medium', 'Large'] and make sure the category is ordered in the same order\n    category_name_2:                               # Force this column to be converted to a category (no particular order)\n  dates: ['record_date']                           # Force these columns to be treated as a date_time, expand all date sub-fields into different columns (e.g. 'yyyy', 'mm', 'dd', 'day_of_week'... etc.)\n  ont_hot: ['Enclosure_Type']                      # All columns listed here are converted to one hot encoding\n  one_hot_max_cardinality: 7                       # All columns having less then this number of categories are converted to one hot encoding\n  std_threshold: 0.0                               # Drop columns of having standard deviation less or equal than this threshold", 
            "title": "YAML config: Dataset section"
        }, 
        {
            "location": "/index2/#dataset-load", 
            "text": "This step typical attempts to load data from files (e.g. load a \"data frame\" or a set of images).   Attempt to load from pickle file ( {dataset_path}/{dataset_name}.pkl ). If the files exists, load the dataset.  Invoke a user defined function decorated with  @dataset_load .  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, so  Log(ML)  will attempt to create a dataset (next step)  Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_load  The dataset is marked to be saved", 
            "title": "Dataset: Load"
        }, 
        {
            "location": "/index2/#dataset-create", 
            "text": "This part creates a dataset by invoking the user defined function decorated by  @dataset_create \n1. If the dataset has been loaded (i.e. \"Load dataset\" step was successful), skip this step\n1. Invoke a user defined function decorated with  @dataset_create :\n    - If there is no user defined function or the section is disabled in the config file (i.e.  enable=False ), this step fails. Since  Log(ML)  doesn't have a dataset to work with (load and create steps both failed) it will exit with an error.\n    - Parameters to the user defined function are defined in config YAML file section  functions , sub-section  dataset_create \n    - The return value from the user defined function is used as a dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset load default implementation for  dataset_type='df'  (i.e. DataFrame) reads a dataFrame from a CSV file using  pandas.read_csv", 
            "title": "Dataset: Create"
        }, 
        {
            "location": "/index2/#dataset-transform", 
            "text": "This step is used to make changes to dataset to make is usable, for instance converting string values into numerical categories.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_transform :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_transform \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved  DataFrames:  Dataset transform default implementation for  dataset_type='df'  (i.e. DataFrame)     Expand date/time features  Convert to categorical  Convert to one-hot  Missing data  Drop low standard deviation fields   Expand date/time features :  Fields defined in the config YAML file, section  dataset , sub-section  dates  are treated as date/time when the dataFrame CSV is loaded and then expanded into several columns:  [Year, Month, Day, DayOfWeek, Hour, Minute, Second, etc.] .  Convert to categorical :  Fields defined in the config YAML file, section  dataset , sub-section  categories  are converted into categorical data and converted to a numerical (integer) representation. Category  -1  represents missing values.  Convert to one-hot :  Fields defined in the config YAML file, section  dataset , sub-section  ont_hot  are converted into one-hot encoding.\nAlso, any categorical field that has a cardinality (i.e. number of categories) equal or less then  one_hot_max_cardinality  is converted to one-hot encoding.  If there are missing values, a column  *_isna  is added to the one-hot encoding.  Missing data :  In any column having missing values that was not converted to date, categorical or one-hot; a new column  *_na  is created (where the value is '1' if the field has missing a value) and the missing values are replaced by the median of the non-missing values.  Drop low standard deviation fields  All fields having standard deviation equal or lower than  std_threshold  (by default  0.0 ) are dropped. Using the default value ( std_threshold=0.0 ) this means dropping all fields having the exact same value for all samples.", 
            "title": "Dataset: Transform"
        }, 
        {
            "location": "/index2/#dataset-augment", 
            "text": "This step invokes the user defined function  @augment  to perform dataset augmentation\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been augmented), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_augment :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_augment \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Augment"
        }, 
        {
            "location": "/index2/#dataset-preprocess", 
            "text": "This step is used to pre-process data in order to make the dataset compatible with the inputs required by the model (e.g. normalize values)\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been pre-processed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_preprocess :\n    - If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, no error is produced.\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_preprocess \n    - The return value replaces the original dataset\n    - The dataset is marked to be saved", 
            "title": "Dataset: Preprocess"
        }, 
        {
            "location": "/index2/#dataset-split", 
            "text": "This step us used to split the dataset into \"train\", \"test\" and \"validation\" datasets.\n1. If this step has already been performed (i.e. a dataset loaded from a pickle file that has already been transformed), the step is skipped\n1. Invoke a user defined function decorated with  @dataset_split :\n    1. If there is no user defined function  @dataset_split  or the section is disabled in the config file (i.e.  enable=False ), this step has failed (no error is produced) attempt to use a default implementation of \"dataset split\".\n    - Parameters: The first parameter is the dataset. Other parameters are defined in config YAML file section  functions , sub-section  dataset_split \n    - If the function is invoked, the return value must be a tuple of three datasets:  (dataset_train, dataset_test, dataset_validate) \n    - The return value from the function replaces the original dataset (specifically, each value replaces the train/test/validate datasets)\n    - The dataset is marked to be saved\n1. Attempt to use a default implementation of \"dataset split\"\n    - If config YAML parameter  is_use_default_split  is set to  False , the split step failed (no error is produced)\n    - The default split implementation attempts to split the dataset in three parts, defined by config YAML file parameters  split_test  and  split_validate  in section  dataset_split . If these parameters are not defined in the config YAML file, the split section failed (no error is produced)", 
            "title": "Dataset: Split"
        }, 
        {
            "location": "/index2/#dataset-save", 
            "text": "If the dataset is marked to be saved in any of the previous steps, attempt to save the dataset.   If the the YAML config variable  do_not_save  is set to  True , this step is skipped  If a user defined function decorated with  @dataset_save  exists, it is invoked  Parameters: The first four parameters are  dataset, dataset_train, dataset_test, dataset_validate . Other parameters are defined in config YAML file section  functions , sub-section  dataset_save    Otherwise the dataset is saved to the pickle file  {dataset_path}/{dataset_name}.pkl", 
            "title": "Dataset: Save"
        }, 
        {
            "location": "/index2/#main-workflow-model", 
            "text": "In these steps we create and train models. This also takes care of common tasks, such as hyper-parameter optimization, cross-validation and model analysis.  The main steps are:   Model Create:  @model_create  Model Train:  @model_train  Model Save:  @model_save  Model Save train results  Model Test:  @model_evaluate  Model Validate:  @model_evaluate   A new  model_id  is created each time a new model is created/trained. This is used to make sure that files created during a run do not collision with other files names from previous runs. The  model_id  has the format  yyyymmdd_hhmmss.counter  where:\n    -  yyyy ,  mm ,  dd ,  hh ,  mm ,  ss : Current year, month, day, hour, minute, second (UTC time)\n    -  counter : Number of models created in this  Log(ML)  run (increasing counter starting with  1 ).  Logging : All results from STDOUT and STDERR are saved to  {model_path}/{model_name}.parameters.{model_id}.stdout  and  {model_path}/{model_name}.parameters.{model_id}.stderr  respectively. Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each output set to different  stdout/stderr  files (see details below).", 
            "title": "Main workflow: Model"
        }, 
        {
            "location": "/index2/#yaml-config-model-section", 
            "text": "model:\n  model_name: 'MyModel'              # Model name: A simple string to use for file names related to this model\n  model_path: 'path/to/dir'          # Train path: A path where to store logs and data from training\n  is_save_model_pickle: False        # Try to save model using a pickle file?\n  is_save_model_method: True         # Try to save model using a pickle file?\n  is_save_model_method_ext: 'model'  # Model file extension\n  is_save_test_pickle: True          # Save model test results to a pickle file?\n  is_save_train_pickle: False        # Save model train results to pickle file?\n  is_save_validate_pickle: False     # Save model validation results to pickle file?", 
            "title": "YAML config: Model section"
        }, 
        {
            "location": "/index2/#model-create", 
            "text": "Create a new model, to be trained. It also saves the parameters used to create the model to a YAML file.   If a user defined function decorated with  @model_create  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameter is  dataset_train  if the dataset was split, otherwise is the full dataset. Other parameters are defined in config YAML file section  functions , sub-section  model_create  The return value from the user defined function is stored as the  model    Current parameters are saved to a YAML file  {model_path}/{model_name}.parameters.{model_id}.yaml . Note that  model_id  is included in the path, so creating several models in the same  Log(ML)  run would save each parameter set to different YAML files.", 
            "title": "Model: Create"
        }, 
        {
            "location": "/index2/#model-train", 
            "text": "Train the model.   If a user defined function decorated with  @model_train  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_train  (if the dataset was split, otherwise is the full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_train  The return value from the user defined function is stored as the  train_results  (these result will be saved, see later steps)", 
            "title": "Model: Train"
        }, 
        {
            "location": "/index2/#model-save", 
            "text": "Save the (trained) model.   If a user defined function decorated with  @model_save  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program tries to save using a pickle file (see next step).  Parameters: The first parameters is the  model . Other parameters are defined in config YAML file section  functions , sub-section  model_save  Return successful    Attempt to save model to pickle file if previous step ( @model_save  function) failed.  If parameter  is_save_model_pickle  from config YAML file is set to  False , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.model.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save each model to different pickle files.    Attempt to save model to using  model.save()  if previous step failed.  If parameter  is_save_model_method  from config YAML file is set to  False , this step is skipped  Invoke model's method  model.save({file_name}) , where  file_name  is set to  {model_path}/{model_name}.model.{model_id}.{is_save_model_method_ext}  (parameter  is_save_model_method_ext  is defined in config YAML file)", 
            "title": "Model: Save"
        }, 
        {
            "location": "/index2/#model-save-train-results", 
            "text": "Save results from training to a pickle file   Attempt to save model training results (i.e. the return value from  @model_train  function) to pickle.  If parameter  is_save_train_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.train_results.{model_id}.pkl .  Note that  model_id  is included in the path, so training several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save train Results"
        }, 
        {
            "location": "/index2/#model-test", 
            "text": "Evaluate the model on the  dataset_test  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_test  (if the dataset was split, otherwise use full dataset). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  test_results  (these result will be saved, see later steps)", 
            "title": "Model: Test"
        }, 
        {
            "location": "/index2/#model-save-test-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_test  parameter) to pickle.  If parameter  is_save_test_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.test_results.{model_id}.pkl .  Note that  model_id  is included in the path, so testing several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save test results"
        }, 
        {
            "location": "/index2/#model-validate", 
            "text": "Evaluate the model on the  dataset_validate  dataset_test   If a user defined function decorated with  @model_evaluate  exists, it is invoked  If there is no function or the section is disabled in the config file (i.e.  enable=False ), this step has failed, the program exits with an error.  Parameters: The first parameters are  model  and  dataset_validate  (if the dataset was split, otherwise this step fails). Other parameters are defined in config YAML file section  functions , sub-section  model_evaluate  The return value from the user defined function is stored as the  validate_results  (these result will be saved, see later steps)", 
            "title": "Model: Validate"
        }, 
        {
            "location": "/index2/#model-save-validate-results", 
            "text": "Attempt to save model test results (i.e. the return value from  @model_evaluate  function invoked with  dataset_validate  parameter) to pickle.  If parameter  is_save_validate_pickle  from config YAML file is set to  False , this step is skipped  If the results are  None , this step is skipped  The model resulting from training is saved to a pickle file file  {model_path}/{model_name}.validate_results.{model_id}.pkl .  Note that  model_id  is included in the path, so validating several models in the same  Log(ML)  run would save train results to different pickle files.", 
            "title": "Model: Save validate results"
        }, 
        {
            "location": "/index2/#alternative-workflows", 
            "text": "There are some  Log(ML)  workflows that run \"dataset\" and \"model\" workflows several times:\n1. Hyper-parameter optimization\n1. Cross-validation", 
            "title": "Alternative workflows"
        }, 
        {
            "location": "/index2/#alternative-workflow-hyper-parameter-optimization", 
            "text": "This workflow allows to perform hyper-parameter optimization using a Bayesian framework ( hyper-opt ). The hyper parameters can be optimized in several stages of the \"dataset\" and \"model\".  The hyper-parameter optimization workflow adds a bayesian optimization on top of the main workflow. This means that, conceptually, it's executing the main workflow several times using a bayesian optimizer.  The hyper-parameter optimizaition method used is HyperOpt, for details see  Hyperopt documentation  Typically, hyper-parameter optimization is used to tune model training parameters.  Log(ML)  also allows to tune model creation parameters, as well as data augmentation and preprocessing parameters.", 
            "title": "Alternative workflow: Hyper-parameter optimization"
        }, 
        {
            "location": "/index2/#yaml-config", 
            "text": "YAML configuration of hyper parameter optimization: All parameter are defined in the  hyper_parameter_optimization  section.  hyper_parameter_optimization:\n    enable: False                   # Set this to 'True' or comment out to enable hyper-parameter optimization\n    show_progressbar: True          # Show progress bar\n    algorithm: 'tpe'                # Algorithm: 'tpe' (Bayesian Tree of Parzen Estimators), 'random' (random search)\n    max_evals: 100                  # Max number of hyper-parameter evaluations. Keep in mnd that each evaluation is a full model training    # Parameter space to explore\n    space:                          # Parameters search space specification, add one section for each user defined function you want to optimize\n        dataset_augment:                    # Add parameter space specification for each part you want to optimize (see examples below)\n        dataset_create:\n        dataset_preprocess:\n        model_create:\n        model_train:  Search space : We define parameters for each part we want to optimize (e.g.  preprocess ,  model_create , etc.).\nThe format for each parameter space is:  parameter_name: ['distribution', distribution)parameters...]  For distribution names and parameters, see:  section 'Parameter Expressions'  Important: The parameters space definition should be a subset of the parameters in each  function  section.  Example: Perform hyper-parameter optimization of the learning rate using a uniform distribution as a p  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]  hyper_parameter_optimization:\n    algorithm: 'tpe'\n    max_evals: 100\n    space:\n        dataset_preprocess:\n          num_x: ['choice', [100, 200, 300, 400, 500]]\n          num_y: ['choice', [20, 50, 100, 200]]\n        model_create:\n            layer_1: ['randint', 20]\n            layer_2: ['randint', 10]\n        model_train:\n            learning_rate: ['uniform', 0.0, 0.5]", 
            "title": "YAML config"
        }, 
        {
            "location": "/index2/#alternative-workflow-cross-validation", 
            "text": "This workflow is a Cross-Validation method built on top of the Train part of  Log(ML)  main workflow.  The YAML configuration is quite simple, you need to enable cross-validation and then specify the cross-validation type and the parameters:\nThe cross-validation workflow is implemented using SciKit learn's cross validation, on the methods and parameters see  SciKit's documentation  cross_validation:\n    enable: True    # Set this to 'True' to enable cross validation\n    # Select one of the following algorithms and set the parameters\n    KFold:\n        n_splits: 5\n    # RepeatedKFold:\n    #     n_splits: 5\n    #     n_repeats: 2\n    # LeaveOneOut:\n    # LeavePOut:\n    #     p: 2\n    # ShuffleSplit:\n    #     n_splits: 5\n    #     test_size: 0.25", 
            "title": "Alternative workflow: Cross-validation"
        }, 
        {
            "location": "/index2/#alternative-workflow-data-exploration", 
            "text": "These steps implement feature exploration and importance analysis.   Feature statistics  Co-linearity analysis  Feature importance", 
            "title": "Alternative workflow: Data exploration"
        }, 
        {
            "location": "/index2/#command-line-argument", 
            "text": "Command line options when invoking a  Log(ML)  program:  -c  config.yaml  : Specify a YAML config file\n-d               : Debug mode, show lots of internal messages\n-v               : Verbose", 
            "title": "Command line argument"
        }, 
        {
            "location": "/index2/#model-search", 
            "text": "ada_boost_classifier  ada_boost_regressor  ard_regression  bagging_classifier  bagging_regressor  bayesian_ridge  bernoulli_nb  complement_nb  decision_tree_classifier  decision_tree_regressor  dummy_classifier_most_frequent  dummy_classifier_prior  dummy_classifier_stratified  dummy_classifier_uniform  dummy_regressor_mean  dummy_regressor_median  elastic_net_cv  extra_trees_classifier  extra_trees_regressor  gaussian_nb  gradient_boosting_classifier  gradient_boosting_regressor  hist_gradient_boosting_classifier  hist_gradient_boosting_regressor  huber_regressor  k_neighbors_classifier  k_neighbors_regressor  lars_regression  lasso_cv_regression  lasso_regression  linear_regression  linear_svc  linear_svr  logistic_regression_cv  multinomial_nb  nearest_centroid  nu_svc  nu_svr  orthogonal_matching_pursuit_regression  passive_aggressive_classifier  perceptron  radius_neighbors_classifier  radius_neighbors_regressor  random_forest_classifier  random_forest_regressor  ransac_regressor  ridge_cv_regression  ridge_regression  svc  svr  theil_sen_regressor", 
            "title": "Model Search"
        }, 
        {
            "location": "/index2/#model-search-with-hyper-parameter-optimization", 
            "text": "extra_trees_classifier  extra_trees_regressor  gradient_boosting_classifier  gradient_boosting_regressor  k_neighbors_classifier  k_neighbors_regressor  random_forest_classifier  random_forest_regressor", 
            "title": "Model Search with Hyper-parameter optimization:"
        }
    ]
}